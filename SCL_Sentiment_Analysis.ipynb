{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCL - Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2RuiKMcxZrdK",
        "ymnvrmCK19td",
        "IWI2QLlmuOgn",
        "LhaVtVA2_W82",
        "UzpQlGuPP1zh",
        "LWZsz3t9ufRP",
        "Wi56MBHduYQI",
        "Mbg9X_GLj-j4",
        "PfV_8hA8kT4O"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a52614aa2d314fcf8afd47d81ee62c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dac812d524134e89ab70ee48f08497b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_258ebc5d34304f94aaf4642cc43a5da3",
              "IPY_MODEL_5a7a24f3cc49471ab5b3d3f89bad40e7"
            ]
          }
        },
        "dac812d524134e89ab70ee48f08497b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "258ebc5d34304f94aaf4642cc43a5da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9af2b34327ee4525b042a529c61142b4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06a59e8acdd64527a2d4bcba1ef90be3"
          }
        },
        "5a7a24f3cc49471ab5b3d3f89bad40e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a185bb0005ca4ae3888efb6c80ed6c76",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.33MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2a65ee5053d4a36a05f6e8d8724409b"
          }
        },
        "9af2b34327ee4525b042a529c61142b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06a59e8acdd64527a2d4bcba1ef90be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a185bb0005ca4ae3888efb6c80ed6c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2a65ee5053d4a36a05f6e8d8724409b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fe8713d275d4e6da1f16e75c3e3a2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a7cf68d50bf44279b03f67d8858e7eef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a4e001132254db2ab4c32536cb3ad1a",
              "IPY_MODEL_a9cbd3b4d1f34873b30bce694e327787"
            ]
          }
        },
        "a7cf68d50bf44279b03f67d8858e7eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a4e001132254db2ab4c32536cb3ad1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a518d9bb967c429a884169d83242b9b1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99a6ff12c8b04a57a9b4e5dd0922e438"
          }
        },
        "a9cbd3b4d1f34873b30bce694e327787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_330cc60383ac4e328207d0fb95676bc2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:03&lt;00:00, 156B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_870acbee2bbe4df9b786bdbd247b5ebc"
          }
        },
        "a518d9bb967c429a884169d83242b9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99a6ff12c8b04a57a9b4e5dd0922e438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "330cc60383ac4e328207d0fb95676bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "870acbee2bbe4df9b786bdbd247b5ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa089f6f160143d9bf4784c0a73bc543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b00fc2d521445debfafc60a5bf3db13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b21de39c6ef44516bd7865753ef9872a",
              "IPY_MODEL_1b55be8b4f1a482297e76e3844beecad"
            ]
          }
        },
        "9b00fc2d521445debfafc60a5bf3db13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b21de39c6ef44516bd7865753ef9872a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a93d028c0ec41b590fa0e04217c119b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_835384f11e7449569a99227b637d400b"
          }
        },
        "1b55be8b4f1a482297e76e3844beecad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa9bf006a03947ee9343b59fb663b0b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:02&lt;00:00, 1.78MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6684f06a158e47efa503a609b610d609"
          }
        },
        "8a93d028c0ec41b590fa0e04217c119b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "835384f11e7449569a99227b637d400b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa9bf006a03947ee9343b59fb663b0b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6684f06a158e47efa503a609b610d609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52c6cf331b3143e8868dff576b1199ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc468847a0ff48f0be6c1f95c738b90a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9b2741590304a169d53335f9c6f42cb",
              "IPY_MODEL_4f25478ff1a34e758e934109e10f8fd0"
            ]
          }
        },
        "dc468847a0ff48f0be6c1f95c738b90a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9b2741590304a169d53335f9c6f42cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eda53a1c2a1f43b886925ce83e64b13b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1885418496,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1885418496,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67b19c08c7fb4481a5b5edc684de1116"
          }
        },
        "4f25478ff1a34e758e934109e10f8fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_959bfb31f0b94392a8eca3f875e25570",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.89G/1.89G [00:29&lt;00:00, 64.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5bae6633d314c01996359c1303a1117"
          }
        },
        "eda53a1c2a1f43b886925ce83e64b13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67b19c08c7fb4481a5b5edc684de1116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "959bfb31f0b94392a8eca3f875e25570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5bae6633d314c01996359c1303a1117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeeJin/SCL/blob/master/SCL_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5OJoiCs5HF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOE7GBykpS_f",
        "colab_type": "text"
      },
      "source": [
        "## Load dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGvAusjX69IR",
        "colab_type": "text"
      },
      "source": [
        "##### For TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OitPLX1a66w_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb87fba1-213f-411b-80f6-600e6461ebe6"
      },
      "source": [
        "import os\n",
        "try:\n",
        "    device_name = os.environ['COLAB_TPU_ADDR']\n",
        "    TPU_ADDRESS = 'grpc://' + device_name\n",
        "    print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "\n",
        "except KeyError:\n",
        "    print('TPU not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found TPU at: grpc://10.92.11.42:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsFmbZTl67t4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "02f109ca-9d78-46e2-e7fe-a3b1d07127aa"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "    \n",
        "# Select appropriate distribution strategy\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.92.11.42:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.92.11.42:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.92.11.42:8470']\n",
            "Number of accelerators:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvFYMogD6_7W",
        "colab_type": "text"
      },
      "source": [
        "##### For GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXG03sFLKOpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f4a5b00-2576-4c68-d1c9-de31d99ea464"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXk26NSLKJjq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c49404d5-74a3-4036-b36c-9bc656ececf0"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6I0CMLy-SJw",
        "colab_type": "text"
      },
      "source": [
        "##### Required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyFz8AlJ-HWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nlpaug -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hgCYN_15DFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "16a929fc-b80f-4eeb-fd72-85b00195f3ae"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 3.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 15.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=87ab6ea0e6a2344cbcbacea2ca203c59c65f473d017444712283b3689d2b375a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAtdWFG46Bl2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "562f0738-da12-4f8e-a1eb-ac51af50a133"
      },
      "source": [
        "!pip install emoji --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=d484548c4480b1d416ff69ee02b88e0b55bb8a2f96fb1f5d309232dcf08623d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ecbx4D1pTzz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "939a5ac9-c842-4607-9d85-e3d5bf302358"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import seaborn as sb\n",
        "sb.set()\n",
        "\n",
        "# For Data Cleaning\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "\n",
        "# For LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# For BERT\n",
        "# from transformers import BertTokenizer\n",
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "# from transformers import get_linear_schedule_with_warmup\n",
        "# from torch.utils.data import TensorDataset, random_split\n",
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "import time\n",
        "import datetime\n",
        "import emoji\n",
        "\n",
        "# For XLM-RoBERTa\n",
        "import transformers\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na4OIyzxpMXf",
        "colab_type": "text"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd5cGcbkpLNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "bc2a2fe9-5bec-4e9c-fdfa-c134f2a256b3"
      },
      "source": [
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HviKsNYTqP9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66e8bd91-fa07-476a-ea9a-e70c431ed788"
      },
      "source": [
        "%cd ../gdrive/My\\ Drive/student-shopee-code-league-sentiment-analysis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/student-shopee-code-league-sentiment-analysis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUuSwQXxqZHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c5b85430-2816-4325-bb24-a1c1430019d4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT_epoch_1_3labs.pth\tBERT_poor_epoch_1.pth  sampleSubmission.csv\n",
            "BERT_epoch_2_3labs.pth\tBERT_poor_epoch_2.pth  test.csv\n",
            "BERT_good_epoch.pth\tcheckpoints\t       train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwqYZJ-Gqbab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample = pd.read_csv('sampleSubmission.csv')\n",
        "# sample.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kVUHQSYqbXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "a79a16b3-0564-4605-9e0f-25417191fb71"
      },
      "source": [
        "train_raw = pd.read_csv('train.csv')\n",
        "print(len(train_raw))\n",
        "train_raw.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "146811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Ga disappointed neat products .. Meletot Hilsn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Rdtanya replace broken glass, broken chargernya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Nyesel bngt dsni shopping antecedent photo mes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sent a light blue suit goods ga want a refund</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Pendants came with dents and scratches on its ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Dg yg depending being sent in photos</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Hours not a hologram</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Shop fraudulent business. we put two lamps, on...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Well, according to Price</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Pictures and names of elise 7154, but the bran...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review  rating\n",
              "0          0  Ga disappointed neat products .. Meletot Hilsn...       1\n",
              "1          1    Rdtanya replace broken glass, broken chargernya       1\n",
              "2          2  Nyesel bngt dsni shopping antecedent photo mes...       1\n",
              "3          3      Sent a light blue suit goods ga want a refund       1\n",
              "4          4  Pendants came with dents and scratches on its ...       1\n",
              "5          5               Dg yg depending being sent in photos       1\n",
              "6          6                               Hours not a hologram       1\n",
              "7          7  Shop fraudulent business. we put two lamps, on...       1\n",
              "8          8                           Well, according to Price       1\n",
              "9          9  Pictures and names of elise 7154, but the bran...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TZ5zggNqbUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "2d02a0a4-fd09-4a91-948c-ff0aeb307f60"
      },
      "source": [
        "test_raw = pd.read_csv('test.csv')\n",
        "print(len(test_raw))\n",
        "test_raw.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Great danger, cool, motif and cantik2 jg model...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>One of the shades don't fit well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Very comfortable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Fast delivery. Product expiry is on Dec 2022. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>it's sooooo cute! i like playing with the glit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>They 're about a 1/2 inch longer than the broo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>The quality not good and receved the slipper i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Nice quality of Cotton &amp; cute .. design .. acc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>which is easy as can be ( just lifting up the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Shipping was fast too soon, ordered Tuesday to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review\n",
              "0          1  Great danger, cool, motif and cantik2 jg model...\n",
              "1          2                   One of the shades don't fit well\n",
              "2          3                                   Very comfortable\n",
              "3          4  Fast delivery. Product expiry is on Dec 2022. ...\n",
              "4          5  it's sooooo cute! i like playing with the glit...\n",
              "5          6  They 're about a 1/2 inch longer than the broo...\n",
              "6          7  The quality not good and receved the slipper i...\n",
              "7          8  Nice quality of Cotton & cute .. design .. acc...\n",
              "8          9  which is easy as can be ( just lifting up the ...\n",
              "9         10  Shipping was fast too soon, ordered Tuesday to..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K50ushKSpDaJ",
        "colab_type": "text"
      },
      "source": [
        "## Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8NjOyZ_uKDd",
        "colab_type": "text"
      },
      "source": [
        "### Let's look at the rating distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_5SGyuZpAy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "f6f161d1-b9b3-4daf-e7e5-cfd74fdba9d1"
      },
      "source": [
        "train_raw.groupby(by = 'rating').agg('count')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14785</td>\n",
              "      <td>14785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12705</td>\n",
              "      <td>12705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35941</td>\n",
              "      <td>35941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41865</td>\n",
              "      <td>41865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>41515</td>\n",
              "      <td>41515</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        review_id  review\n",
              "rating                   \n",
              "1           14785   14785\n",
              "2           12705   12705\n",
              "3           35941   35941\n",
              "4           41865   41865\n",
              "5           41515   41515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSBYVvkypAtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "4ffe9811-a90b-44b5-ba58-a54f86a92b89"
      },
      "source": [
        "sb.catplot(x = 'rating', data = train_raw, kind = 'count')\n",
        "sb.set_style('whitegrid')\n",
        "train_raw.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_id     int64\n",
              "review       object\n",
              "rating        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr4ItbrP2v7g",
        "colab_type": "text"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0mCU-gnutZm",
        "colab_type": "text"
      },
      "source": [
        "### Change 'rating' column from long format to wide format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OpiSBhpu3zo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "d1a3a60d-c057-4ac3-9ba2-1c71f2592d3b"
      },
      "source": [
        "# creating instance of one-hot-encoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc_df = pd.DataFrame(enc.fit_transform(train_raw[['rating']]).toarray())\n",
        "\n",
        "print(len(enc_df))\n",
        "enc_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "146811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4\n",
              "0  1.0  0.0  0.0  0.0  0.0\n",
              "1  1.0  0.0  0.0  0.0  0.0\n",
              "2  1.0  0.0  0.0  0.0  0.0\n",
              "3  1.0  0.0  0.0  0.0  0.0\n",
              "4  1.0  0.0  0.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FjIgs2wu3uX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "7c159d2e-9467-456a-a543-c5e6706d04d0"
      },
      "source": [
        "# train_df = train_raw.drop(['rating'], axis = 1)\n",
        "# train_df = pd.concat([train_df.reset_index(drop=True), enc_df.reset_index(drop=True)], axis=1)\n",
        "train_df = train_raw\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Ga disappointed neat products .. Meletot Hilsn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Rdtanya replace broken glass, broken chargernya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Nyesel bngt dsni shopping antecedent photo mes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sent a light blue suit goods ga want a refund</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Pendants came with dents and scratches on its ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review  rating\n",
              "0          0  Ga disappointed neat products .. Meletot Hilsn...       1\n",
              "1          1    Rdtanya replace broken glass, broken chargernya       1\n",
              "2          2  Nyesel bngt dsni shopping antecedent photo mes...       1\n",
              "3          3      Sent a light blue suit goods ga want a refund       1\n",
              "4          4  Pendants came with dents and scratches on its ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFc9SGYd1bOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e519451d-d9ca-479c-aedd-560c858e92b6"
      },
      "source": [
        "train_df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_id     int64\n",
              "review       object\n",
              "rating        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o23bs7NV4aXN",
        "colab_type": "text"
      },
      "source": [
        "### Clean comments text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l_hyx1cXke1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "663554da-b2df-4f29-96d7-4e9f03948f20"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Ga disappointed neat products .. Meletot Hilsn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Rdtanya replace broken glass, broken chargernya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Nyesel bngt dsni shopping antecedent photo mes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sent a light blue suit goods ga want a refund</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Pendants came with dents and scratches on its ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review  rating\n",
              "0          0  Ga disappointed neat products .. Meletot Hilsn...       1\n",
              "1          1    Rdtanya replace broken glass, broken chargernya       1\n",
              "2          2  Nyesel bngt dsni shopping antecedent photo mes...       1\n",
              "3          3      Sent a light blue suit goods ga want a refund       1\n",
              "4          4  Pendants came with dents and scratches on its ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmn63OCfjgks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5933e891-ab29-4a74-e515-fa75449e6d8a"
      },
      "source": [
        "have_emoji_train_idx = []\n",
        "have_emoji_test_idx = []\n",
        "\n",
        "for idx, review in enumerate(train_df['review']):\n",
        "    if any(char in emoji.UNICODE_EMOJI for char in review):\n",
        "        have_emoji_train_idx.append(idx)\n",
        "        \n",
        "for idx, review in enumerate(test_raw['review']):\n",
        "    if any(char in emoji.UNICODE_EMOJI for char in review):\n",
        "        have_emoji_test_idx.append(idx)\n",
        "\n",
        "print(len(have_emoji_train_idx))\n",
        "print(len(have_emoji_test_idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20048\n",
            "7582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1imR8Ep8vsn9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "65daa681-3772-46e7-bedd-66ee4f4c43b2"
      },
      "source": [
        "repeated_rows_train = []\n",
        "repeated_rows_test = []\n",
        "\n",
        "for idx, review in enumerate(train_df['review']):\n",
        "    if re.match(r'\\w*(\\w)\\1+', review):\n",
        "        repeated_rows_train.append(idx)\n",
        "        \n",
        "for idx, review in enumerate(test_raw['review']):\n",
        "    if re.match(r'\\w*(\\w)\\1+', review):\n",
        "        repeated_rows_test.append(idx)\n",
        "\n",
        "print(len(repeated_rows_train))\n",
        "print(len(repeated_rows_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26146\n",
            "10336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2m8u3r04fNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New function 'clean_text' created\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\n', '', text)\n",
        "    text = re.sub(r':\\(', 'dislike', text)\n",
        "    text = re.sub(r': \\(\\(', 'dislike', text)\n",
        "    text = re.sub(r':, \\(', 'dislike', text)\n",
        "    text = re.sub(r':\\)', 'smile', text)\n",
        "    text = re.sub(r';\\)', 'smile', text)\n",
        "    text = re.sub(r':\\)\\)\\)', 'smile', text)\n",
        "    text = re.sub(r':\\)\\)\\)\\)\\)\\)', 'smile', text)\n",
        "    text = re.sub(r'=\\)\\)\\)\\)', 'smile', text)\n",
        "    text = re.sub('[^a-z0-9 ]', ' ', text)\n",
        "    tokenizer = text.split()\n",
        "    return ' '.join([text for text in tokenizer])\n",
        "\n",
        "# remove emojis\n",
        "# def remove_emoji(text):\n",
        "#   try:\n",
        "#     return emoji.get_emoji_regexp().sub(u'', text)\n",
        "#   except:\n",
        "#     print(text)\n",
        "#     return text\n",
        "def remove_emoji(text):\n",
        "    \n",
        "    # Change emoji to text\n",
        "    text = emoji.demojize(text).replace(\":\", \" \")\n",
        "    \n",
        "    # Delete repeated emoji\n",
        "    tokenizer = text.split()\n",
        "    repeated_list = []\n",
        "    \n",
        "    for word in tokenizer:\n",
        "        if word not in repeated_list:\n",
        "            repeated_list.append(word)\n",
        "    \n",
        "    text = ' '.join(text for text in repeated_list)\n",
        "    text = text.replace(\"_\", \" \").replace(\"-\", \" \")\n",
        "    return text\n",
        "\n",
        "def delete_repeated_char(text):\n",
        "    \n",
        "    text = re.sub(r'(\\w)\\1{2,}', r'\\1', text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5yTP-utZiL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2155854a-55ff-44ce-f7f8-bc2adf2ea913"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKbhvYxi4fLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c318a3e9-8416-411a-db55-f1204f63865d"
      },
      "source": [
        "# Removing stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def removestop(comrev):\n",
        "    comrev = ' '.join(word for word in str(comrev).split() if word not in stop_words)\n",
        "    return comrev\n",
        "\n",
        "print(removestop(\"sent a light blue suit goods ga want a refund\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sent light blue suit goods ga want refund\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6wsWcvM4fQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "949f21dd-4856-44e4-fcb3-953ce361e5bb"
      },
      "source": [
        "train_df['review'] = train_df['review'].astype(str)\n",
        "train_df['review'] = train_df['review'].apply(lambda x: clean_text(x))\n",
        "train_df.loc[have_emoji_train_idx, 'review'] = train_df.loc[have_emoji_train_idx, 'review'].apply(remove_emoji)\n",
        "train_df['review'] = train_df['review'].apply(lambda x: removestop(x))\n",
        "train_df.loc[repeated_rows_train, 'review'] = train_df.loc[repeated_rows_train, 'review'].apply(delete_repeated_char)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ga disappointed neat products meletot hilsnyaa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rdtanya replace broken glass broken chargernya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>nyesel bngt dsni shopping antecedent photo mes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sent light blue suit goods ga want refund</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>pendants came dents scratches surface coating ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review  rating\n",
              "0          0  ga disappointed neat products meletot hilsnyaa...       1\n",
              "1          1     rdtanya replace broken glass broken chargernya       1\n",
              "2          2  nyesel bngt dsni shopping antecedent photo mes...       1\n",
              "3          3          sent light blue suit goods ga want refund       1\n",
              "4          4  pendants came dents scratches surface coating ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFr8tbU8vtlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop the row that has noisy text or mislabeled rating\n",
        "noisy_row = [31, 50, 2235, 5244, 10409, 11748, 12384, 14395, 15215, 17629, 20819, 23691, 32089, 39532, 40530, 43954, 48186, 50500, 55834, 60088,\n",
        "             60442, 61095, 62982, 63803, 67464, 70791, 74861, 73636, 74119, 76275, 79789, 85745, 91058, 91663, 91800, 93204, 99295, 100903, 101177, 103155,\n",
        "             109166, 109566, 109651, 109724, 110115, 110441, 111461, 113175, 115782, 116903, 118099, 118328, 118414, 119071, 125338, 125340, 129496, 129640, \n",
        "             132027, 138212, 131626, 134715, 133248, 136217, 141377, 143707, 145045, 146485, 37301, 6845, 15058, 30591, 59747, 95165]\n",
        "\n",
        "train_df.drop(noisy_row, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeDt3iu4J7Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "have_emoji_train_idx = []\n",
        "repeated_rows_train = []\n",
        "noisy_row = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RuiKMcxZrdK",
        "colab_type": "text"
      },
      "source": [
        "### Split into 3 categories first\n",
        "1, 2 --> 0: Poor  \n",
        "   3 --> 1: Neutral  \n",
        "4, 5 --> 2: Good"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPtJVWoqbGf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_rating(rating):\n",
        "  if rating == 1 or rating == 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  elif rating == 4 or rating == 5:\n",
        "    return 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrylU6ksbsHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40468c72-4840-444e-8995-82578e2c6e66"
      },
      "source": [
        "conv_rating(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I2dxJ48Z6pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['rating'] = train_df['rating'].apply(lambda x: conv_rating(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-HZcDrGZ6ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "030ecea4-a807-4676-8775-c65993ac5d97"
      },
      "source": [
        "# train_df[train_df['rating']==0]\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ga disappointed neat products meletot hilsnyaa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rdtanya replace broken glass broken chargernya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>nyesel bngt dsni shopping antecedent photo mes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sent light blue suit goods ga want refund</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>pendants came dents scratches surface coating ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review  rating\n",
              "0          0  ga disappointed neat products meletot hilsnyaa...       1\n",
              "1          1     rdtanya replace broken glass broken chargernya       1\n",
              "2          2  nyesel bngt dsni shopping antecedent photo mes...       1\n",
              "3          3          sent light blue suit goods ga want refund       1\n",
              "4          4  pendants came dents scratches surface coating ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPoY5NvIcOyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "94d89c68-b9a6-4035-93ac-eb4eff591970"
      },
      "source": [
        "sb.catplot(x = 'rating', data = train_df, kind = 'count')\n",
        "sb.set_style('whitegrid')\n",
        "train_raw.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_id     int64\n",
              "review       object\n",
              "rating        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymnvrmCK19td",
        "colab_type": "text"
      },
      "source": [
        "### Take specific ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuMffquQ2CeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "fbdd3c40-8f1e-4e45-da2a-0ff0321fd4d9"
      },
      "source": [
        "rating_4 = train_df[train_df['rating']==4]\n",
        "rating_5 = train_df[train_df['rating']==5]\n",
        "train_df = pd.concat([rating_4, rating_5])\n",
        "print(len(train_df))\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83380\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63431</th>\n",
              "      <td>63431</td>\n",
              "      <td>product price good good delivery speed</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63432</th>\n",
              "      <td>63432</td>\n",
              "      <td>children super happy although rich gift kinder...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63433</th>\n",
              "      <td>63433</td>\n",
              "      <td>beautiful bag thought little put phone</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63434</th>\n",
              "      <td>63434</td>\n",
              "      <td>thanks sis sa freebie till next purchase</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63435</th>\n",
              "      <td>63435</td>\n",
              "      <td>product quality excellent original product ori...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       review_id                                             review  rating\n",
              "63431      63431             product price good good delivery speed       4\n",
              "63432      63432  children super happy although rich gift kinder...       4\n",
              "63433      63433             beautiful bag thought little put phone       4\n",
              "63434      63434           thanks sis sa freebie till next purchase       4\n",
              "63435      63435  product quality excellent original product ori...       4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWI2QLlmuOgn",
        "colab_type": "text"
      },
      "source": [
        "### Try to sample the data until all ratings are around 15k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahtmeBDapAnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "49a122a5-7929-4e2d-e898-f494b11958b3"
      },
      "source": [
        "rating_1 = train_df[train_df['rating']==1].iloc[:15000]\n",
        "rating_1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ga disappointed neat products meletot hilsnyaa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rdtanya replace broken glass broken chargernya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>nyesel bngt dsni shopping antecedent photo mes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sent light blue suit goods ga want refund</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>pendants came dents scratches surface coating ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review  rating\n",
              "0          0  ga disappointed neat products meletot hilsnyaa...       1\n",
              "1          1     rdtanya replace broken glass broken chargernya       1\n",
              "2          2  nyesel bngt dsni shopping antecedent photo mes...       1\n",
              "3          3          sent light blue suit goods ga want refund       1\n",
              "4          4  pendants came dents scratches surface coating ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSyomc3LZTlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rating_2 = train_df[train_df['rating']==2].iloc[:15000]\n",
        "rating_3 = train_df[train_df['rating']==3].iloc[:15000]\n",
        "rating_4 = train_df[train_df['rating']==4].iloc[:15000]\n",
        "rating_5 = train_df[train_df['rating']==5].iloc[:15000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jskcxC13uWWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "cf10e25e-9db2-449d-95a7-42f910a23c9a"
      },
      "source": [
        "train_df = pd.concat([rating_1, rating_2, rating_3, rating_4, rating_5])\n",
        "print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72490, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ga disappointed neat products meletot hilsnyaa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>rdtanya replace broken glass broken chargernya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>nyesel bngt dsni shopping antecedent photo mes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sent light blue suit goods ga want refund</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>pendants came dents scratches surface coating ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review  rating\n",
              "0          0  ga disappointed neat products meletot hilsnyaa...       1\n",
              "1          1     rdtanya replace broken glass broken chargernya       1\n",
              "2          2  nyesel bngt dsni shopping antecedent photo mes...       1\n",
              "3          3          sent light blue suit goods ga want refund       1\n",
              "4          4  pendants came dents scratches surface coating ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLUahczvdKDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "964c8974-4e6d-466a-d970-b10227c80561"
      },
      "source": [
        "sb.catplot(x = 'rating', data = train_df, kind = 'count')\n",
        "sb.set_style('whitegrid')\n",
        "train_df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review_id     int64\n",
              "review       object\n",
              "rating        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQCKXc7F98u6",
        "colab_type": "text"
      },
      "source": [
        "### Text augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNhCqpym98bL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_augmented = []\n",
        "\n",
        "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', action='insert')\n",
        "\n",
        "for review in train_df['review']:\n",
        "    augmented_text = aug.augment(review)\n",
        "    review_augmented.append(augmented_text)\n",
        "\n",
        "train_aug = pd.DataFrame({'review': review_augmented,\n",
        "                          'rating': train_df['rating']})\n",
        "\n",
        "train_aug[train_aug['review'].str.len() >= 10].to_csv('review_aug_insert.csv', index=False)\n",
        "\n",
        "train_aug =  pd.read_csv('./train_aug.csv')\n",
        "\n",
        "train_df = pd.concat([train_df, train_aug], axis=0, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdmdEeWO23fr",
        "colab_type": "text"
      },
      "source": [
        "### Split data into train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVMLUXfl27wx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "067f463c-5e8f-4e91-b5e2-2f3ea8041302"
      },
      "source": [
        "#shuffle\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5611</td>\n",
              "      <td>buy clothes l intersects bits eat type ji</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110936</td>\n",
              "      <td>excellent product quality excellent product pr...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90852</td>\n",
              "      <td>good product quality well priced product deliv...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8422</td>\n",
              "      <td>unsatisfactory quality tight cloth</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>131786</td>\n",
              "      <td>right choice buy cemilan2 millennial packing n...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review  rating\n",
              "0       5611          buy clothes l intersects bits eat type ji       1\n",
              "1     110936  excellent product quality excellent product pr...       5\n",
              "2      90852  good product quality well priced product deliv...       4\n",
              "3       8422                 unsatisfactory quality tight cloth       1\n",
              "4     131786  right choice buy cemilan2 millennial packing n...       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdlXlxsCaoSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abd45210-95c7-4e14-bad9-08cfaa30038b"
      },
      "source": [
        "train_df[\"review\"].iloc[53]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'alhamdulillah always happy shopping diladyfame addition material quality affordable price good fast delivery thanks ladyfame ku'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S717ApAqdRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34579d7e-98eb-449b-a991-b1e1b6019702"
      },
      "source": [
        "train_df[\"rating\"].iloc[53]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNK5wfPs58KP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train_df[\"review\"].values\n",
        "# y_train = train_df[[0, 1, 2, 3, 4]].values\n",
        "y_train = train_df[\"rating\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp8znocs6U5i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "74a9d8da-9c47-4db9-8e7b-d6ee6657c12f"
      },
      "source": [
        "print(X_train[:3])\n",
        "print(y_train[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['nice value money' 'nice blouse'\n",
            " 'product quality excellent original product']\n",
            "[4 5 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhaVtVA2_W82",
        "colab_type": "text"
      },
      "source": [
        "##### For basic LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VDK5IuXQ8gV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words = 1000\n",
        "max_len = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQZZGjZG6l-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "X_train = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PtLy9kw64RE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "5930e6b8-2f70-4eac-f864-985bea10aa04"
      },
      "source": [
        "X_train[111]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNFkCLrZ8i9h",
        "colab_type": "text"
      },
      "source": [
        "##### For BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tWaCLML8lic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "a52614aa2d314fcf8afd47d81ee62c50",
            "dac812d524134e89ab70ee48f08497b4",
            "258ebc5d34304f94aaf4642cc43a5da3",
            "5a7a24f3cc49471ab5b3d3f89bad40e7",
            "9af2b34327ee4525b042a529c61142b4",
            "06a59e8acdd64527a2d4bcba1ef90be3",
            "a185bb0005ca4ae3888efb6c80ed6c76",
            "d2a65ee5053d4a36a05f6e8d8724409b"
          ]
        },
        "outputId": "beb9d4d1-3f9f-4bdc-e3d9-cec241381fc5"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a52614aa2d314fcf8afd47d81ee62c50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbz57pnF1-O9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ff65f0b0-dc41-41d1-96b4-7e6a1597228c"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', X_train[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(X_train[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X_train[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  big finally g kepake\n",
            "Tokenized:  ['big', 'finally', 'g', 'ke', '##pa', '##ke']\n",
            "Token IDs:  [2502, 2633, 1043, 17710, 4502, 3489]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NF7r2wr85JB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7aab17cf-828a-4d62-a696-534528788f83"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for rev in X_train:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(rev, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWaVi2m_9Kkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "95546145-81e4-469e-9b06-68b9075da901"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for rev in X_train:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        rev,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 210,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation = True\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(y_train)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', X_train[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  nice value money\n",
            "Token IDs: tensor([ 101, 3835, 3643, 2769,  102,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uePa9Ri8N9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regular_encode(texts, tokenizer, maxlen=512):\n",
        "    enc_di = tokenizer.batch_encode_plus(\n",
        "             texts, \n",
        "             return_attention_mask=False, \n",
        "             return_token_type_ids=False,\n",
        "             pad_to_max_length=True,\n",
        "             max_length = maxlen,\n",
        "             truncation = True)\n",
        "    \n",
        "    return np.array(enc_di['input_ids'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvp3qSpi9Rqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rating_mapper_encode = {1: 0,\n",
        "                        2: 1,\n",
        "                        3: 2,\n",
        "                        4: 3,\n",
        "                        5: 4}\n",
        "\n",
        "train_df['rating'] = train_df['rating'].map(rating_mapper_encode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTQ3t6bkAe3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "35c060ba-8e26-438e-8774-ddfb8048b290"
      },
      "source": [
        "train_df.head(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5611</td>\n",
              "      <td>buy clothes l intersects bits eat type ji</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110936</td>\n",
              "      <td>excellent product quality excellent product pr...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90852</td>\n",
              "      <td>good product quality well priced product deliv...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8422</td>\n",
              "      <td>unsatisfactory quality tight cloth</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>131786</td>\n",
              "      <td>right choice buy cemilan2 millennial packing n...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>97573</td>\n",
              "      <td>son love</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review  rating\n",
              "0       5611          buy clothes l intersects bits eat type ji       0\n",
              "1     110936  excellent product quality excellent product pr...       4\n",
              "2      90852  good product quality well priced product deliv...       3\n",
              "3       8422                 unsatisfactory quality tight cloth       0\n",
              "4     131786  right choice buy cemilan2 millennial packing n...       4\n",
              "5      97573                                           son love       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzpQlGuPP1zh",
        "colab_type": "text"
      },
      "source": [
        "## Data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33GcpD_0LmN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ad02bed-7e57-473e-9f08-d8f4d8b1da9e"
      },
      "source": [
        "labels[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 4, 4, 5, 5, 5, 4, 4, 5, 5, 5, 4, 5, 4, 5, 4, 5, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7znLmf6L6GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels -= 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUfCneqAL-HO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "280007a5-0341-4ce1-9308-1c8f8ca35495"
      },
      "source": [
        "labels[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbcadYYr0x1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e81ce12e-3c27-4986-83fc-a90cda8950c2"
      },
      "source": [
        "type(input_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-I5WsvNP5JS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d170d033-e7d6-4525-8c60-d00125cda256"
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66,704 training samples\n",
            "16,676 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYd7K8-wQGqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUgM8-g6pE9i",
        "colab_type": "text"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB5O1DPco8eR",
        "colab_type": "text"
      },
      "source": [
        "### Simple LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWZsz3t9ufRP",
        "colab_type": "text"
      },
      "source": [
        "###### 1st try: just using raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg1J_6umo4vX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Inp = Input(name='inputs',shape=[max_len])\n",
        "x = Embedding(max_words,50,input_length = max_len)(Inp)\n",
        "x = LSTM(64, name='LSTM_1')(x)\n",
        "x = Dense(512, activation='relu',name='Dense_1')(x)\n",
        "x = Dropout(0.5, name='Dropout_1')(x)\n",
        "x = Dense(512, activation='relu',name='Dense_2')(x)\n",
        "x = Dropout(0.5, name='Dropout_2')(x)\n",
        "out = Dense(5, activation='softmax', name='output')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLIWFpW5uaRt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "75a22274-a300-4168-8bdc-f96aa7cc005d"
      },
      "source": [
        "model = Model(inputs=Inp,outputs=out)\n",
        "model.compile(loss='binary_crossentropy',optimizer=Adam(lr = 0.001), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 150, 50)           50000     \n",
            "_________________________________________________________________\n",
            "LSTM_1 (LSTM)                (None, 64)                29440     \n",
            "_________________________________________________________________\n",
            "Dense_1 (Dense)              (None, 512)               33280     \n",
            "_________________________________________________________________\n",
            "Dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "Dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "Dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 377,941\n",
            "Trainable params: 377,941\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60wQpKGW9z8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa56ad7f-12f6-4b0e-c999-c81a81bb694b"
      },
      "source": [
        "# !mkdir checkpoints\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints  sampleSubmission.csv  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiXfcVP47-X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.0001, patience = 5)\n",
        "checkpoint = ModelCheckpoint(filepath=\"./checkpoints/LSTM_best_weights_2.hdf5\",\n",
        "                             save_best_only = True,  # Only save a model if `val_loss` has improved.\n",
        "                             monitor = \"val_loss\",\n",
        "                             verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Au_q7847-SX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "cb5affb6-f327-4285-dcd1-b4aa3b305713"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size = 128,\n",
        "                    epochs = 15,\n",
        "                    validation_split = 0.1,\n",
        "                    callbacks = [early_stop, checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1033/1033 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.4399\n",
            "Epoch 00001: val_loss improved from inf to 0.36864, saving model to ./checkpoints/LSTM_best_weights.hdf5\n",
            "1033/1033 [==============================] - 13s 13ms/step - loss: 0.3946 - accuracy: 0.4399 - val_loss: 0.3686 - val_accuracy: 0.4694\n",
            "Epoch 2/15\n",
            "1030/1033 [============================>.] - ETA: 0s - loss: 0.3648 - accuracy: 0.4820\n",
            "Epoch 00002: val_loss improved from 0.36864 to 0.36015, saving model to ./checkpoints/LSTM_best_weights.hdf5\n",
            "1033/1033 [==============================] - 13s 13ms/step - loss: 0.3647 - accuracy: 0.4821 - val_loss: 0.3601 - val_accuracy: 0.4834\n",
            "Epoch 3/15\n",
            "1032/1033 [============================>.] - ETA: 0s - loss: 0.3594 - accuracy: 0.4879\n",
            "Epoch 00003: val_loss improved from 0.36015 to 0.35875, saving model to ./checkpoints/LSTM_best_weights.hdf5\n",
            "1033/1033 [==============================] - 13s 13ms/step - loss: 0.3593 - accuracy: 0.4879 - val_loss: 0.3587 - val_accuracy: 0.4802\n",
            "Epoch 4/15\n",
            "1031/1033 [============================>.] - ETA: 0s - loss: 0.3553 - accuracy: 0.4936\n",
            "Epoch 00004: val_loss improved from 0.35875 to 0.35717, saving model to ./checkpoints/LSTM_best_weights.hdf5\n",
            "1033/1033 [==============================] - 13s 12ms/step - loss: 0.3554 - accuracy: 0.4936 - val_loss: 0.3572 - val_accuracy: 0.4879\n",
            "Epoch 5/15\n",
            "1030/1033 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.4971\n",
            "Epoch 00005: val_loss improved from 0.35717 to 0.35557, saving model to ./checkpoints/LSTM_best_weights.hdf5\n",
            "1033/1033 [==============================] - 13s 12ms/step - loss: 0.3528 - accuracy: 0.4971 - val_loss: 0.3556 - val_accuracy: 0.4886\n",
            "Epoch 6/15\n",
            "1031/1033 [============================>.] - ETA: 0s - loss: 0.3503 - accuracy: 0.4973\n",
            "Epoch 00006: val_loss did not improve from 0.35557\n",
            "1033/1033 [==============================] - 12s 12ms/step - loss: 0.3504 - accuracy: 0.4972 - val_loss: 0.3563 - val_accuracy: 0.4847\n",
            "Epoch 7/15\n",
            "1030/1033 [============================>.] - ETA: 0s - loss: 0.3484 - accuracy: 0.5002\n",
            "Epoch 00007: val_loss did not improve from 0.35557\n",
            "1033/1033 [==============================] - 12s 12ms/step - loss: 0.3484 - accuracy: 0.5002 - val_loss: 0.3556 - val_accuracy: 0.4820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1QBc4Em_0wQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "73b8fe9e-bb59-4436-db76-025f2db8c037"
      },
      "source": [
        "history_1 = model.fit(X_train, y_train,\n",
        "                    batch_size = 128,\n",
        "                    epochs = 15,\n",
        "                    validation_split = 0.1,\n",
        "                    callbacks = [early_stop, checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1033/1033 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.4519\n",
            "Epoch 00001: val_loss improved from inf to 0.37329, saving model to ./checkpoints/LSTM_best_weights_1.hdf5\n",
            "1033/1033 [==============================] - 16s 15ms/step - loss: 0.3832 - accuracy: 0.4519 - val_loss: 0.3733 - val_accuracy: 0.4625\n",
            "Epoch 2/15\n",
            "1030/1033 [============================>.] - ETA: 0s - loss: 0.3642 - accuracy: 0.4806\n",
            "Epoch 00002: val_loss improved from 0.37329 to 0.36218, saving model to ./checkpoints/LSTM_best_weights_1.hdf5\n",
            "1033/1033 [==============================] - 15s 15ms/step - loss: 0.3642 - accuracy: 0.4806 - val_loss: 0.3622 - val_accuracy: 0.4824\n",
            "Epoch 3/15\n",
            "1033/1033 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.4862\n",
            "Epoch 00003: val_loss improved from 0.36218 to 0.35946, saving model to ./checkpoints/LSTM_best_weights_1.hdf5\n",
            "1033/1033 [==============================] - 15s 15ms/step - loss: 0.3590 - accuracy: 0.4862 - val_loss: 0.3595 - val_accuracy: 0.4772\n",
            "Epoch 4/15\n",
            "1031/1033 [============================>.] - ETA: 0s - loss: 0.3561 - accuracy: 0.4900\n",
            "Epoch 00004: val_loss improved from 0.35946 to 0.35751, saving model to ./checkpoints/LSTM_best_weights_1.hdf5\n",
            "1033/1033 [==============================] - 15s 15ms/step - loss: 0.3561 - accuracy: 0.4900 - val_loss: 0.3575 - val_accuracy: 0.4785\n",
            "Epoch 5/15\n",
            "1033/1033 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.4943\n",
            "Epoch 00005: val_loss improved from 0.35751 to 0.35639, saving model to ./checkpoints/LSTM_best_weights_1.hdf5\n",
            "1033/1033 [==============================] - 15s 15ms/step - loss: 0.3536 - accuracy: 0.4943 - val_loss: 0.3564 - val_accuracy: 0.4877\n",
            "Epoch 6/15\n",
            "1032/1033 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.4979\n",
            "Epoch 00006: val_loss improved from 0.35639 to 0.35606, saving model to ./checkpoints/LSTM_best_weights_1.hdf5\n",
            "1033/1033 [==============================] - 16s 15ms/step - loss: 0.3509 - accuracy: 0.4979 - val_loss: 0.3561 - val_accuracy: 0.4869\n",
            "Epoch 7/15\n",
            "1032/1033 [============================>.] - ETA: 0s - loss: 0.3487 - accuracy: 0.5012\n",
            "Epoch 00007: val_loss did not improve from 0.35606\n",
            "1033/1033 [==============================] - 15s 14ms/step - loss: 0.3488 - accuracy: 0.5012 - val_loss: 0.3562 - val_accuracy: 0.4889\n",
            "Epoch 8/15\n",
            "1031/1033 [============================>.] - ETA: 0s - loss: 0.3466 - accuracy: 0.5036\n",
            "Epoch 00008: val_loss did not improve from 0.35606\n",
            "1033/1033 [==============================] - 15s 14ms/step - loss: 0.3465 - accuracy: 0.5035 - val_loss: 0.3587 - val_accuracy: 0.4837\n",
            "Epoch 9/15\n",
            "1032/1033 [============================>.] - ETA: 0s - loss: 0.3450 - accuracy: 0.5073\n",
            "Epoch 00009: val_loss did not improve from 0.35606\n",
            "1033/1033 [==============================] - 15s 14ms/step - loss: 0.3450 - accuracy: 0.5072 - val_loss: 0.3563 - val_accuracy: 0.4875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wl9rTEobUid",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "outputId": "92cc32b3-f0c0-4f71-ff34-90e55ffb0c1e"
      },
      "source": [
        "history_2 = model.fit(X_train, y_train,\n",
        "                    batch_size = 128,\n",
        "                    epochs = 20,\n",
        "                    validation_split = 0.1,\n",
        "                    callbacks = [early_stop, checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1033/1033 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.4299\n",
            "Epoch 00001: val_loss improved from inf to 0.38284, saving model to ./checkpoints/LSTM_best_weights_2.hdf5\n",
            "1033/1033 [==============================] - 13s 13ms/step - loss: 0.3957 - accuracy: 0.4299 - val_loss: 0.3828 - val_accuracy: 0.4497\n",
            "Epoch 2/20\n",
            "1031/1033 [============================>.] - ETA: 0s - loss: 0.3772 - accuracy: 0.4620\n",
            "Epoch 00002: val_loss improved from 0.38284 to 0.37291, saving model to ./checkpoints/LSTM_best_weights_2.hdf5\n",
            "1033/1033 [==============================] - 13s 12ms/step - loss: 0.3773 - accuracy: 0.4620 - val_loss: 0.3729 - val_accuracy: 0.4662\n",
            "Epoch 3/20\n",
            "1030/1033 [============================>.] - ETA: 0s - loss: 0.3722 - accuracy: 0.4680\n",
            "Epoch 00003: val_loss improved from 0.37291 to 0.36937, saving model to ./checkpoints/LSTM_best_weights_2.hdf5\n",
            "1033/1033 [==============================] - 12s 12ms/step - loss: 0.3722 - accuracy: 0.4682 - val_loss: 0.3694 - val_accuracy: 0.4744\n",
            "Epoch 4/20\n",
            "1031/1033 [============================>.] - ETA: 0s - loss: 0.3689 - accuracy: 0.4746\n",
            "Epoch 00004: val_loss improved from 0.36937 to 0.36901, saving model to ./checkpoints/LSTM_best_weights_2.hdf5\n",
            "1033/1033 [==============================] - 12s 12ms/step - loss: 0.3689 - accuracy: 0.4746 - val_loss: 0.3690 - val_accuracy: 0.4741\n",
            "Epoch 5/20\n",
            "1029/1033 [============================>.] - ETA: 0s - loss: 0.3664 - accuracy: 0.4755\n",
            "Epoch 00005: val_loss did not improve from 0.36901\n",
            "1033/1033 [==============================] - 12s 12ms/step - loss: 0.3664 - accuracy: 0.4755 - val_loss: 0.3699 - val_accuracy: 0.4749\n",
            "Epoch 6/20\n",
            "1032/1033 [============================>.] - ETA: 0s - loss: 0.3642 - accuracy: 0.4797\n",
            "Epoch 00006: val_loss improved from 0.36901 to 0.36742, saving model to ./checkpoints/LSTM_best_weights_2.hdf5\n",
            "1033/1033 [==============================] - 12s 12ms/step - loss: 0.3642 - accuracy: 0.4797 - val_loss: 0.3674 - val_accuracy: 0.4730\n",
            "Epoch 7/20\n",
            "1033/1033 [==============================] - ETA: 0s - loss: 0.3625 - accuracy: 0.4784\n",
            "Epoch 00007: val_loss did not improve from 0.36742\n",
            "1033/1033 [==============================] - 12s 12ms/step - loss: 0.3625 - accuracy: 0.4784 - val_loss: 0.3676 - val_accuracy: 0.4805\n",
            "Epoch 8/20\n",
            "1030/1033 [============================>.] - ETA: 0s - loss: 0.3605 - accuracy: 0.4834\n",
            "Epoch 00008: val_loss did not improve from 0.36742\n",
            "1033/1033 [==============================] - 12s 11ms/step - loss: 0.3605 - accuracy: 0.4834 - val_loss: 0.3687 - val_accuracy: 0.4710\n",
            "Epoch 9/20\n",
            "1029/1033 [============================>.] - ETA: 0s - loss: 0.3586 - accuracy: 0.4861\n",
            "Epoch 00009: val_loss did not improve from 0.36742\n",
            "1033/1033 [==============================] - 12s 11ms/step - loss: 0.3586 - accuracy: 0.4860 - val_loss: 0.3679 - val_accuracy: 0.4730\n",
            "Epoch 10/20\n",
            "1033/1033 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.4882\n",
            "Epoch 00010: val_loss did not improve from 0.36742\n",
            "1033/1033 [==============================] - 12s 11ms/step - loss: 0.3566 - accuracy: 0.4882 - val_loss: 0.3691 - val_accuracy: 0.4724\n",
            "Epoch 11/20\n",
            "1033/1033 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.4908\n",
            "Epoch 00011: val_loss did not improve from 0.36742\n",
            "1033/1033 [==============================] - 12s 11ms/step - loss: 0.3547 - accuracy: 0.4908 - val_loss: 0.3694 - val_accuracy: 0.4689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi56MBHduYQI",
        "colab_type": "text"
      },
      "source": [
        "### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDmlQPvruZW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f98eca31-8ecf-4197-c29b-06c906601875"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2,    \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rSF411tuaqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "5200355e-03a6-43a3-fcda-db339b17bb8c"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4ZVSBZgQ7CO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHM28kIgRNhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEpYhqmqRNb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhystbc-Rk-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function for formatting elapsed times as hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx8cABWi4Vy9",
        "colab_type": "text"
      },
      "source": [
        "##### BERT 5 labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBmUZ4Z3RlB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4216f3d-4282-4000-e785-9ccf27ae9484"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "    torch.save(model.state_dict(), \"./BERT_{epoch_i}.pth\")\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  2,039.    Elapsed: 0:01:15.\n",
            "  Batch    80  of  2,039.    Elapsed: 0:02:31.\n",
            "  Batch   120  of  2,039.    Elapsed: 0:03:46.\n",
            "  Batch   160  of  2,039.    Elapsed: 0:05:02.\n",
            "  Batch   200  of  2,039.    Elapsed: 0:06:17.\n",
            "  Batch   240  of  2,039.    Elapsed: 0:07:33.\n",
            "  Batch   280  of  2,039.    Elapsed: 0:08:48.\n",
            "  Batch   320  of  2,039.    Elapsed: 0:10:03.\n",
            "  Batch   360  of  2,039.    Elapsed: 0:11:19.\n",
            "  Batch   400  of  2,039.    Elapsed: 0:12:34.\n",
            "  Batch   440  of  2,039.    Elapsed: 0:13:50.\n",
            "  Batch   480  of  2,039.    Elapsed: 0:15:05.\n",
            "  Batch   520  of  2,039.    Elapsed: 0:16:20.\n",
            "  Batch   560  of  2,039.    Elapsed: 0:17:36.\n",
            "  Batch   600  of  2,039.    Elapsed: 0:18:51.\n",
            "  Batch   640  of  2,039.    Elapsed: 0:20:07.\n",
            "  Batch   680  of  2,039.    Elapsed: 0:21:22.\n",
            "  Batch   720  of  2,039.    Elapsed: 0:22:38.\n",
            "  Batch   760  of  2,039.    Elapsed: 0:23:53.\n",
            "  Batch   800  of  2,039.    Elapsed: 0:25:08.\n",
            "  Batch   840  of  2,039.    Elapsed: 0:26:23.\n",
            "  Batch   880  of  2,039.    Elapsed: 0:27:38.\n",
            "  Batch   920  of  2,039.    Elapsed: 0:28:54.\n",
            "  Batch   960  of  2,039.    Elapsed: 0:30:09.\n",
            "  Batch 1,000  of  2,039.    Elapsed: 0:31:24.\n",
            "  Batch 1,040  of  2,039.    Elapsed: 0:32:40.\n",
            "  Batch 1,080  of  2,039.    Elapsed: 0:33:55.\n",
            "  Batch 1,120  of  2,039.    Elapsed: 0:35:11.\n",
            "  Batch 1,160  of  2,039.    Elapsed: 0:36:26.\n",
            "  Batch 1,200  of  2,039.    Elapsed: 0:37:42.\n",
            "  Batch 1,240  of  2,039.    Elapsed: 0:38:57.\n",
            "  Batch 1,280  of  2,039.    Elapsed: 0:40:12.\n",
            "  Batch 1,320  of  2,039.    Elapsed: 0:41:28.\n",
            "  Batch 1,360  of  2,039.    Elapsed: 0:42:43.\n",
            "  Batch 1,400  of  2,039.    Elapsed: 0:43:59.\n",
            "  Batch 1,440  of  2,039.    Elapsed: 0:45:14.\n",
            "  Batch 1,480  of  2,039.    Elapsed: 0:46:29.\n",
            "  Batch 1,520  of  2,039.    Elapsed: 0:47:45.\n",
            "  Batch 1,560  of  2,039.    Elapsed: 0:49:00.\n",
            "  Batch 1,600  of  2,039.    Elapsed: 0:50:15.\n",
            "  Batch 1,640  of  2,039.    Elapsed: 0:51:31.\n",
            "  Batch 1,680  of  2,039.    Elapsed: 0:52:46.\n",
            "  Batch 1,720  of  2,039.    Elapsed: 0:54:02.\n",
            "  Batch 1,760  of  2,039.    Elapsed: 0:55:17.\n",
            "  Batch 1,800  of  2,039.    Elapsed: 0:56:32.\n",
            "  Batch 1,840  of  2,039.    Elapsed: 0:57:48.\n",
            "  Batch 1,880  of  2,039.    Elapsed: 0:59:03.\n",
            "  Batch 1,920  of  2,039.    Elapsed: 1:00:19.\n",
            "  Batch 1,960  of  2,039.    Elapsed: 1:01:34.\n",
            "  Batch 2,000  of  2,039.    Elapsed: 1:02:49.\n",
            "\n",
            "  Average training loss: 1.16\n",
            "  Training epcoh took: 1:04:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:02:39\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  2,039.    Elapsed: 0:01:15.\n",
            "  Batch    80  of  2,039.    Elapsed: 0:02:31.\n",
            "  Batch   120  of  2,039.    Elapsed: 0:03:46.\n",
            "  Batch   160  of  2,039.    Elapsed: 0:05:02.\n",
            "  Batch   200  of  2,039.    Elapsed: 0:06:17.\n",
            "  Batch   240  of  2,039.    Elapsed: 0:07:33.\n",
            "  Batch   280  of  2,039.    Elapsed: 0:08:48.\n",
            "  Batch   320  of  2,039.    Elapsed: 0:10:04.\n",
            "  Batch   360  of  2,039.    Elapsed: 0:11:19.\n",
            "  Batch   400  of  2,039.    Elapsed: 0:12:34.\n",
            "  Batch   440  of  2,039.    Elapsed: 0:13:50.\n",
            "  Batch   480  of  2,039.    Elapsed: 0:15:05.\n",
            "  Batch   520  of  2,039.    Elapsed: 0:16:21.\n",
            "  Batch   560  of  2,039.    Elapsed: 0:17:36.\n",
            "  Batch   600  of  2,039.    Elapsed: 0:18:52.\n",
            "  Batch   640  of  2,039.    Elapsed: 0:20:07.\n",
            "  Batch   680  of  2,039.    Elapsed: 0:21:23.\n",
            "  Batch   720  of  2,039.    Elapsed: 0:22:38.\n",
            "  Batch   760  of  2,039.    Elapsed: 0:23:54.\n",
            "  Batch   800  of  2,039.    Elapsed: 0:25:09.\n",
            "  Batch   840  of  2,039.    Elapsed: 0:26:25.\n",
            "  Batch   880  of  2,039.    Elapsed: 0:27:40.\n",
            "  Batch   920  of  2,039.    Elapsed: 0:28:56.\n",
            "  Batch   960  of  2,039.    Elapsed: 0:30:11.\n",
            "  Batch 1,000  of  2,039.    Elapsed: 0:31:27.\n",
            "  Batch 1,040  of  2,039.    Elapsed: 0:32:42.\n",
            "  Batch 1,080  of  2,039.    Elapsed: 0:33:58.\n",
            "  Batch 1,120  of  2,039.    Elapsed: 0:35:13.\n",
            "  Batch 1,160  of  2,039.    Elapsed: 0:36:29.\n",
            "  Batch 1,200  of  2,039.    Elapsed: 0:37:44.\n",
            "  Batch 1,240  of  2,039.    Elapsed: 0:39:00.\n",
            "  Batch 1,280  of  2,039.    Elapsed: 0:40:15.\n",
            "  Batch 1,320  of  2,039.    Elapsed: 0:41:31.\n",
            "  Batch 1,360  of  2,039.    Elapsed: 0:42:46.\n",
            "  Batch 1,400  of  2,039.    Elapsed: 0:44:02.\n",
            "  Batch 1,440  of  2,039.    Elapsed: 0:45:17.\n",
            "  Batch 1,480  of  2,039.    Elapsed: 0:46:33.\n",
            "  Batch 1,520  of  2,039.    Elapsed: 0:47:48.\n",
            "  Batch 1,560  of  2,039.    Elapsed: 0:49:04.\n",
            "  Batch 1,600  of  2,039.    Elapsed: 0:50:19.\n",
            "  Batch 1,640  of  2,039.    Elapsed: 0:51:35.\n",
            "  Batch 1,680  of  2,039.    Elapsed: 0:52:50.\n",
            "  Batch 1,720  of  2,039.    Elapsed: 0:54:06.\n",
            "  Batch 1,760  of  2,039.    Elapsed: 0:55:21.\n",
            "  Batch 1,800  of  2,039.    Elapsed: 0:56:37.\n",
            "  Batch 1,840  of  2,039.    Elapsed: 0:57:53.\n",
            "  Batch 1,880  of  2,039.    Elapsed: 0:59:08.\n",
            "  Batch 1,920  of  2,039.    Elapsed: 1:00:24.\n",
            "  Batch 1,960  of  2,039.    Elapsed: 1:01:39.\n",
            "  Batch 2,000  of  2,039.    Elapsed: 1:02:55.\n",
            "\n",
            "  Average training loss: 1.02\n",
            "  Training epcoh took: 1:04:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 1.08\n",
            "  Validation took: 0:02:39\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  2,039.    Elapsed: 0:01:15.\n",
            "  Batch    80  of  2,039.    Elapsed: 0:02:31.\n",
            "  Batch   120  of  2,039.    Elapsed: 0:03:46.\n",
            "  Batch   160  of  2,039.    Elapsed: 0:05:02.\n",
            "  Batch   200  of  2,039.    Elapsed: 0:06:17.\n",
            "  Batch   240  of  2,039.    Elapsed: 0:07:33.\n",
            "  Batch   280  of  2,039.    Elapsed: 0:08:48.\n",
            "  Batch   320  of  2,039.    Elapsed: 0:10:04.\n",
            "  Batch   360  of  2,039.    Elapsed: 0:11:19.\n",
            "  Batch   400  of  2,039.    Elapsed: 0:12:35.\n",
            "  Batch   440  of  2,039.    Elapsed: 0:13:50.\n",
            "  Batch   480  of  2,039.    Elapsed: 0:15:06.\n",
            "  Batch   520  of  2,039.    Elapsed: 0:16:21.\n",
            "  Batch   560  of  2,039.    Elapsed: 0:17:37.\n",
            "  Batch   600  of  2,039.    Elapsed: 0:18:52.\n",
            "  Batch   640  of  2,039.    Elapsed: 0:20:08.\n",
            "  Batch   680  of  2,039.    Elapsed: 0:21:23.\n",
            "  Batch   720  of  2,039.    Elapsed: 0:22:39.\n",
            "  Batch   760  of  2,039.    Elapsed: 0:23:54.\n",
            "  Batch   800  of  2,039.    Elapsed: 0:25:10.\n",
            "  Batch   840  of  2,039.    Elapsed: 0:26:25.\n",
            "  Batch   880  of  2,039.    Elapsed: 0:27:41.\n",
            "  Batch   920  of  2,039.    Elapsed: 0:28:56.\n",
            "  Batch   960  of  2,039.    Elapsed: 0:30:12.\n",
            "  Batch 1,000  of  2,039.    Elapsed: 0:31:27.\n",
            "  Batch 1,040  of  2,039.    Elapsed: 0:32:43.\n",
            "  Batch 1,080  of  2,039.    Elapsed: 0:33:58.\n",
            "  Batch 1,120  of  2,039.    Elapsed: 0:35:14.\n",
            "  Batch 1,160  of  2,039.    Elapsed: 0:36:30.\n",
            "  Batch 1,200  of  2,039.    Elapsed: 0:37:45.\n",
            "  Batch 1,240  of  2,039.    Elapsed: 0:39:01.\n",
            "  Batch 1,280  of  2,039.    Elapsed: 0:40:16.\n",
            "  Batch 1,320  of  2,039.    Elapsed: 0:41:32.\n",
            "  Batch 1,360  of  2,039.    Elapsed: 0:42:47.\n",
            "  Batch 1,400  of  2,039.    Elapsed: 0:44:02.\n",
            "  Batch 1,440  of  2,039.    Elapsed: 0:45:18.\n",
            "  Batch 1,480  of  2,039.    Elapsed: 0:46:33.\n",
            "  Batch 1,520  of  2,039.    Elapsed: 0:47:49.\n",
            "  Batch 1,560  of  2,039.    Elapsed: 0:49:04.\n",
            "  Batch 1,600  of  2,039.    Elapsed: 0:50:20.\n",
            "  Batch 1,640  of  2,039.    Elapsed: 0:51:35.\n",
            "  Batch 1,680  of  2,039.    Elapsed: 0:52:51.\n",
            "  Batch 1,720  of  2,039.    Elapsed: 0:54:06.\n",
            "  Batch 1,760  of  2,039.    Elapsed: 0:55:22.\n",
            "  Batch 1,800  of  2,039.    Elapsed: 0:56:37.\n",
            "  Batch 1,840  of  2,039.    Elapsed: 0:57:52.\n",
            "  Batch 1,880  of  2,039.    Elapsed: 0:59:08.\n",
            "  Batch 1,920  of  2,039.    Elapsed: 1:00:23.\n",
            "  Batch 1,960  of  2,039.    Elapsed: 1:01:39.\n",
            "  Batch 2,000  of  2,039.    Elapsed: 1:02:54.\n",
            "\n",
            "  Average training loss: 0.92\n",
            "  Training epcoh took: 1:04:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50\n",
            "  Validation Loss: 1.10\n",
            "  Validation took: 0:02:39\n",
            "\n",
            "Training complete!\n",
            "Total training took 3:20:20 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA7FCtyd0IWP",
        "colab_type": "text"
      },
      "source": [
        "##### Differentiating good, neutral and bad (3 labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unwXXzWiedgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4417efb5-0585-41b9-bbca-cc65fb43ad8a"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "    torch.save(model.state_dict(), './BERT_{epoch_i}.pth')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,130.    Elapsed: 0:01:20.\n",
            "  Batch    80  of  4,130.    Elapsed: 0:02:40.\n",
            "  Batch   120  of  4,130.    Elapsed: 0:04:01.\n",
            "  Batch   160  of  4,130.    Elapsed: 0:05:21.\n",
            "  Batch   200  of  4,130.    Elapsed: 0:06:41.\n",
            "  Batch   240  of  4,130.    Elapsed: 0:08:02.\n",
            "  Batch   280  of  4,130.    Elapsed: 0:09:22.\n",
            "  Batch   320  of  4,130.    Elapsed: 0:10:42.\n",
            "  Batch   360  of  4,130.    Elapsed: 0:12:02.\n",
            "  Batch   400  of  4,130.    Elapsed: 0:13:22.\n",
            "  Batch   440  of  4,130.    Elapsed: 0:14:43.\n",
            "  Batch   480  of  4,130.    Elapsed: 0:16:03.\n",
            "  Batch   520  of  4,130.    Elapsed: 0:17:23.\n",
            "  Batch   560  of  4,130.    Elapsed: 0:18:44.\n",
            "  Batch   600  of  4,130.    Elapsed: 0:20:04.\n",
            "  Batch   640  of  4,130.    Elapsed: 0:21:24.\n",
            "  Batch   680  of  4,130.    Elapsed: 0:22:45.\n",
            "  Batch   720  of  4,130.    Elapsed: 0:24:05.\n",
            "  Batch   760  of  4,130.    Elapsed: 0:25:25.\n",
            "  Batch   800  of  4,130.    Elapsed: 0:26:46.\n",
            "  Batch   840  of  4,130.    Elapsed: 0:28:06.\n",
            "  Batch   880  of  4,130.    Elapsed: 0:29:26.\n",
            "  Batch   920  of  4,130.    Elapsed: 0:30:47.\n",
            "  Batch   960  of  4,130.    Elapsed: 0:32:07.\n",
            "  Batch 1,000  of  4,130.    Elapsed: 0:33:27.\n",
            "  Batch 1,040  of  4,130.    Elapsed: 0:34:48.\n",
            "  Batch 1,080  of  4,130.    Elapsed: 0:36:08.\n",
            "  Batch 1,120  of  4,130.    Elapsed: 0:37:28.\n",
            "  Batch 1,160  of  4,130.    Elapsed: 0:38:49.\n",
            "  Batch 1,200  of  4,130.    Elapsed: 0:40:09.\n",
            "  Batch 1,240  of  4,130.    Elapsed: 0:41:30.\n",
            "  Batch 1,280  of  4,130.    Elapsed: 0:42:50.\n",
            "  Batch 1,320  of  4,130.    Elapsed: 0:44:10.\n",
            "  Batch 1,360  of  4,130.    Elapsed: 0:45:31.\n",
            "  Batch 1,400  of  4,130.    Elapsed: 0:46:51.\n",
            "  Batch 1,440  of  4,130.    Elapsed: 0:48:11.\n",
            "  Batch 1,480  of  4,130.    Elapsed: 0:49:32.\n",
            "  Batch 1,520  of  4,130.    Elapsed: 0:50:52.\n",
            "  Batch 1,560  of  4,130.    Elapsed: 0:52:12.\n",
            "  Batch 1,600  of  4,130.    Elapsed: 0:53:33.\n",
            "  Batch 1,640  of  4,130.    Elapsed: 0:54:53.\n",
            "  Batch 1,680  of  4,130.    Elapsed: 0:56:13.\n",
            "  Batch 1,720  of  4,130.    Elapsed: 0:57:34.\n",
            "  Batch 1,760  of  4,130.    Elapsed: 0:58:54.\n",
            "  Batch 1,800  of  4,130.    Elapsed: 1:00:14.\n",
            "  Batch 1,840  of  4,130.    Elapsed: 1:01:35.\n",
            "  Batch 1,880  of  4,130.    Elapsed: 1:02:55.\n",
            "  Batch 1,920  of  4,130.    Elapsed: 1:04:16.\n",
            "  Batch 1,960  of  4,130.    Elapsed: 1:05:36.\n",
            "  Batch 2,000  of  4,130.    Elapsed: 1:06:56.\n",
            "  Batch 2,040  of  4,130.    Elapsed: 1:08:17.\n",
            "  Batch 2,080  of  4,130.    Elapsed: 1:09:37.\n",
            "  Batch 2,120  of  4,130.    Elapsed: 1:10:58.\n",
            "  Batch 2,160  of  4,130.    Elapsed: 1:12:18.\n",
            "  Batch 2,200  of  4,130.    Elapsed: 1:13:38.\n",
            "  Batch 2,240  of  4,130.    Elapsed: 1:14:59.\n",
            "  Batch 2,280  of  4,130.    Elapsed: 1:16:19.\n",
            "  Batch 2,320  of  4,130.    Elapsed: 1:17:39.\n",
            "  Batch 2,360  of  4,130.    Elapsed: 1:19:00.\n",
            "  Batch 2,400  of  4,130.    Elapsed: 1:20:20.\n",
            "  Batch 2,440  of  4,130.    Elapsed: 1:21:41.\n",
            "  Batch 2,480  of  4,130.    Elapsed: 1:23:01.\n",
            "  Batch 2,520  of  4,130.    Elapsed: 1:24:21.\n",
            "  Batch 2,560  of  4,130.    Elapsed: 1:25:42.\n",
            "  Batch 2,600  of  4,130.    Elapsed: 1:27:02.\n",
            "  Batch 2,640  of  4,130.    Elapsed: 1:28:22.\n",
            "  Batch 2,680  of  4,130.    Elapsed: 1:29:43.\n",
            "  Batch 2,720  of  4,130.    Elapsed: 1:31:03.\n",
            "  Batch 2,760  of  4,130.    Elapsed: 1:32:24.\n",
            "  Batch 2,800  of  4,130.    Elapsed: 1:33:44.\n",
            "  Batch 2,840  of  4,130.    Elapsed: 1:35:04.\n",
            "  Batch 2,880  of  4,130.    Elapsed: 1:36:25.\n",
            "  Batch 2,920  of  4,130.    Elapsed: 1:37:45.\n",
            "  Batch 2,960  of  4,130.    Elapsed: 1:39:05.\n",
            "  Batch 3,000  of  4,130.    Elapsed: 1:40:25.\n",
            "  Batch 3,040  of  4,130.    Elapsed: 1:41:46.\n",
            "  Batch 3,080  of  4,130.    Elapsed: 1:43:06.\n",
            "  Batch 3,120  of  4,130.    Elapsed: 1:44:26.\n",
            "  Batch 3,160  of  4,130.    Elapsed: 1:45:46.\n",
            "  Batch 3,200  of  4,130.    Elapsed: 1:47:06.\n",
            "  Batch 3,240  of  4,130.    Elapsed: 1:48:27.\n",
            "  Batch 3,280  of  4,130.    Elapsed: 1:49:47.\n",
            "  Batch 3,320  of  4,130.    Elapsed: 1:51:07.\n",
            "  Batch 3,360  of  4,130.    Elapsed: 1:52:27.\n",
            "  Batch 3,400  of  4,130.    Elapsed: 1:53:47.\n",
            "  Batch 3,440  of  4,130.    Elapsed: 1:55:07.\n",
            "  Batch 3,480  of  4,130.    Elapsed: 1:56:28.\n",
            "  Batch 3,520  of  4,130.    Elapsed: 1:57:48.\n",
            "  Batch 3,560  of  4,130.    Elapsed: 1:59:08.\n",
            "  Batch 3,600  of  4,130.    Elapsed: 2:00:29.\n",
            "  Batch 3,640  of  4,130.    Elapsed: 2:01:49.\n",
            "  Batch 3,680  of  4,130.    Elapsed: 2:03:09.\n",
            "  Batch 3,720  of  4,130.    Elapsed: 2:04:30.\n",
            "  Batch 3,760  of  4,130.    Elapsed: 2:05:50.\n",
            "  Batch 3,800  of  4,130.    Elapsed: 2:07:10.\n",
            "  Batch 3,840  of  4,130.    Elapsed: 2:08:30.\n",
            "  Batch 3,880  of  4,130.    Elapsed: 2:09:51.\n",
            "  Batch 3,920  of  4,130.    Elapsed: 2:11:11.\n",
            "  Batch 3,960  of  4,130.    Elapsed: 2:12:31.\n",
            "  Batch 4,000  of  4,130.    Elapsed: 2:13:52.\n",
            "  Batch 4,040  of  4,130.    Elapsed: 2:15:12.\n",
            "  Batch 4,080  of  4,130.    Elapsed: 2:16:32.\n",
            "  Batch 4,120  of  4,130.    Elapsed: 2:17:52.\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 2:18:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.57\n",
            "  Validation took: 0:05:43\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,130.    Elapsed: 0:01:20.\n",
            "  Batch    80  of  4,130.    Elapsed: 0:02:40.\n",
            "  Batch   120  of  4,130.    Elapsed: 0:04:01.\n",
            "  Batch   160  of  4,130.    Elapsed: 0:05:21.\n",
            "  Batch   200  of  4,130.    Elapsed: 0:06:41.\n",
            "  Batch   240  of  4,130.    Elapsed: 0:08:01.\n",
            "  Batch   280  of  4,130.    Elapsed: 0:09:22.\n",
            "  Batch   320  of  4,130.    Elapsed: 0:10:42.\n",
            "  Batch   360  of  4,130.    Elapsed: 0:12:02.\n",
            "  Batch   400  of  4,130.    Elapsed: 0:13:23.\n",
            "  Batch   440  of  4,130.    Elapsed: 0:14:43.\n",
            "  Batch   480  of  4,130.    Elapsed: 0:16:03.\n",
            "  Batch   520  of  4,130.    Elapsed: 0:17:24.\n",
            "  Batch   560  of  4,130.    Elapsed: 0:18:44.\n",
            "  Batch   600  of  4,130.    Elapsed: 0:20:04.\n",
            "  Batch   640  of  4,130.    Elapsed: 0:21:25.\n",
            "  Batch   680  of  4,130.    Elapsed: 0:22:45.\n",
            "  Batch   720  of  4,130.    Elapsed: 0:24:05.\n",
            "  Batch   760  of  4,130.    Elapsed: 0:25:26.\n",
            "  Batch   800  of  4,130.    Elapsed: 0:26:46.\n",
            "  Batch   840  of  4,130.    Elapsed: 0:28:07.\n",
            "  Batch   880  of  4,130.    Elapsed: 0:29:27.\n",
            "  Batch   920  of  4,130.    Elapsed: 0:30:47.\n",
            "  Batch   960  of  4,130.    Elapsed: 0:32:08.\n",
            "  Batch 1,000  of  4,130.    Elapsed: 0:33:28.\n",
            "  Batch 1,040  of  4,130.    Elapsed: 0:34:48.\n",
            "  Batch 1,080  of  4,130.    Elapsed: 0:36:09.\n",
            "  Batch 1,120  of  4,130.    Elapsed: 0:37:29.\n",
            "  Batch 1,160  of  4,130.    Elapsed: 0:38:49.\n",
            "  Batch 1,200  of  4,130.    Elapsed: 0:40:10.\n",
            "  Batch 1,240  of  4,130.    Elapsed: 0:41:30.\n",
            "  Batch 1,280  of  4,130.    Elapsed: 0:42:50.\n",
            "  Batch 1,320  of  4,130.    Elapsed: 0:44:11.\n",
            "  Batch 1,360  of  4,130.    Elapsed: 0:45:31.\n",
            "  Batch 1,400  of  4,130.    Elapsed: 0:46:52.\n",
            "  Batch 1,440  of  4,130.    Elapsed: 0:48:12.\n",
            "  Batch 1,480  of  4,130.    Elapsed: 0:49:32.\n",
            "  Batch 1,520  of  4,130.    Elapsed: 0:50:53.\n",
            "  Batch 1,560  of  4,130.    Elapsed: 0:52:13.\n",
            "  Batch 1,600  of  4,130.    Elapsed: 0:53:34.\n",
            "  Batch 1,640  of  4,130.    Elapsed: 0:54:54.\n",
            "  Batch 1,680  of  4,130.    Elapsed: 0:56:15.\n",
            "  Batch 1,720  of  4,130.    Elapsed: 0:57:35.\n",
            "  Batch 1,760  of  4,130.    Elapsed: 0:58:56.\n",
            "  Batch 1,800  of  4,130.    Elapsed: 1:00:16.\n",
            "  Batch 1,840  of  4,130.    Elapsed: 1:01:36.\n",
            "  Batch 1,880  of  4,130.    Elapsed: 1:02:57.\n",
            "  Batch 1,920  of  4,130.    Elapsed: 1:04:17.\n",
            "  Batch 1,960  of  4,130.    Elapsed: 1:05:38.\n",
            "  Batch 2,000  of  4,130.    Elapsed: 1:06:58.\n",
            "  Batch 2,040  of  4,130.    Elapsed: 1:08:19.\n",
            "  Batch 2,080  of  4,130.    Elapsed: 1:09:39.\n",
            "  Batch 2,120  of  4,130.    Elapsed: 1:10:59.\n",
            "  Batch 2,160  of  4,130.    Elapsed: 1:12:20.\n",
            "  Batch 2,200  of  4,130.    Elapsed: 1:13:40.\n",
            "  Batch 2,240  of  4,130.    Elapsed: 1:15:01.\n",
            "  Batch 2,280  of  4,130.    Elapsed: 1:16:21.\n",
            "  Batch 2,320  of  4,130.    Elapsed: 1:17:41.\n",
            "  Batch 2,360  of  4,130.    Elapsed: 1:19:02.\n",
            "  Batch 2,400  of  4,130.    Elapsed: 1:20:22.\n",
            "  Batch 2,440  of  4,130.    Elapsed: 1:21:43.\n",
            "  Batch 2,480  of  4,130.    Elapsed: 1:23:03.\n",
            "  Batch 2,520  of  4,130.    Elapsed: 1:24:23.\n",
            "  Batch 2,560  of  4,130.    Elapsed: 1:25:44.\n",
            "  Batch 2,600  of  4,130.    Elapsed: 1:27:04.\n",
            "  Batch 2,640  of  4,130.    Elapsed: 1:28:24.\n",
            "  Batch 2,680  of  4,130.    Elapsed: 1:29:45.\n",
            "  Batch 2,720  of  4,130.    Elapsed: 1:31:05.\n",
            "  Batch 2,760  of  4,130.    Elapsed: 1:32:26.\n",
            "  Batch 2,800  of  4,130.    Elapsed: 1:33:46.\n",
            "  Batch 2,840  of  4,130.    Elapsed: 1:35:06.\n",
            "  Batch 2,880  of  4,130.    Elapsed: 1:36:27.\n",
            "  Batch 2,920  of  4,130.    Elapsed: 1:37:47.\n",
            "  Batch 2,960  of  4,130.    Elapsed: 1:39:07.\n",
            "  Batch 3,000  of  4,130.    Elapsed: 1:40:28.\n",
            "  Batch 3,040  of  4,130.    Elapsed: 1:41:48.\n",
            "  Batch 3,080  of  4,130.    Elapsed: 1:43:08.\n",
            "  Batch 3,120  of  4,130.    Elapsed: 1:44:29.\n",
            "  Batch 3,160  of  4,130.    Elapsed: 1:45:49.\n",
            "  Batch 3,200  of  4,130.    Elapsed: 1:47:10.\n",
            "  Batch 3,240  of  4,130.    Elapsed: 1:48:30.\n",
            "  Batch 3,280  of  4,130.    Elapsed: 1:49:50.\n",
            "  Batch 3,320  of  4,130.    Elapsed: 1:51:11.\n",
            "  Batch 3,360  of  4,130.    Elapsed: 1:52:31.\n",
            "  Batch 3,400  of  4,130.    Elapsed: 1:53:51.\n",
            "  Batch 3,440  of  4,130.    Elapsed: 1:55:12.\n",
            "  Batch 3,480  of  4,130.    Elapsed: 1:56:32.\n",
            "  Batch 3,520  of  4,130.    Elapsed: 1:57:52.\n",
            "  Batch 3,560  of  4,130.    Elapsed: 1:59:13.\n",
            "  Batch 3,600  of  4,130.    Elapsed: 2:00:33.\n",
            "  Batch 3,640  of  4,130.    Elapsed: 2:01:54.\n",
            "  Batch 3,680  of  4,130.    Elapsed: 2:03:14.\n",
            "  Batch 3,720  of  4,130.    Elapsed: 2:04:34.\n",
            "  Batch 3,760  of  4,130.    Elapsed: 2:05:55.\n",
            "  Batch 3,800  of  4,130.    Elapsed: 2:07:15.\n",
            "  Batch 3,840  of  4,130.    Elapsed: 2:08:36.\n",
            "  Batch 3,880  of  4,130.    Elapsed: 2:09:56.\n",
            "  Batch 3,920  of  4,130.    Elapsed: 2:11:16.\n",
            "  Batch 3,960  of  4,130.    Elapsed: 2:12:37.\n",
            "  Batch 4,000  of  4,130.    Elapsed: 2:13:57.\n",
            "  Batch 4,040  of  4,130.    Elapsed: 2:15:17.\n",
            "  Batch 4,080  of  4,130.    Elapsed: 2:16:38.\n",
            "  Batch 4,120  of  4,130.    Elapsed: 2:17:58.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 2:18:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation Loss: 0.56\n",
            "  Validation took: 0:05:43\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFv1HLKS0Zzd",
        "colab_type": "text"
      },
      "source": [
        "##### Differentiating ratings 4 and 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkPPFXS_0ZhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df15fe66-f816-4e4d-8ff8-8d4343395340"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"This model is to differentiate the '4' ratings from the '5' ratings.\\n\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "    torch.save(model.state_dict(), './BERT_good_epoch.pth')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "This model is to differentiate the '0' ratings from the '1' ratings.\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  2,085.    Elapsed: 0:00:44.\n",
            "  Batch    80  of  2,085.    Elapsed: 0:01:32.\n",
            "  Batch   120  of  2,085.    Elapsed: 0:02:19.\n",
            "  Batch   160  of  2,085.    Elapsed: 0:03:06.\n",
            "  Batch   200  of  2,085.    Elapsed: 0:03:53.\n",
            "  Batch   240  of  2,085.    Elapsed: 0:04:41.\n",
            "  Batch   280  of  2,085.    Elapsed: 0:05:28.\n",
            "  Batch   320  of  2,085.    Elapsed: 0:06:15.\n",
            "  Batch   360  of  2,085.    Elapsed: 0:07:02.\n",
            "  Batch   400  of  2,085.    Elapsed: 0:07:49.\n",
            "  Batch   440  of  2,085.    Elapsed: 0:08:36.\n",
            "  Batch   480  of  2,085.    Elapsed: 0:09:23.\n",
            "  Batch   520  of  2,085.    Elapsed: 0:10:10.\n",
            "  Batch   560  of  2,085.    Elapsed: 0:10:57.\n",
            "  Batch   600  of  2,085.    Elapsed: 0:11:44.\n",
            "  Batch   640  of  2,085.    Elapsed: 0:12:31.\n",
            "  Batch   680  of  2,085.    Elapsed: 0:13:18.\n",
            "  Batch   720  of  2,085.    Elapsed: 0:14:05.\n",
            "  Batch   760  of  2,085.    Elapsed: 0:14:52.\n",
            "  Batch   800  of  2,085.    Elapsed: 0:15:39.\n",
            "  Batch   840  of  2,085.    Elapsed: 0:16:26.\n",
            "  Batch   880  of  2,085.    Elapsed: 0:17:13.\n",
            "  Batch   920  of  2,085.    Elapsed: 0:18:00.\n",
            "  Batch   960  of  2,085.    Elapsed: 0:18:47.\n",
            "  Batch 1,000  of  2,085.    Elapsed: 0:19:34.\n",
            "  Batch 1,040  of  2,085.    Elapsed: 0:20:21.\n",
            "  Batch 1,080  of  2,085.    Elapsed: 0:21:08.\n",
            "  Batch 1,120  of  2,085.    Elapsed: 0:21:55.\n",
            "  Batch 1,160  of  2,085.    Elapsed: 0:22:42.\n",
            "  Batch 1,200  of  2,085.    Elapsed: 0:23:29.\n",
            "  Batch 1,240  of  2,085.    Elapsed: 0:24:16.\n",
            "  Batch 1,280  of  2,085.    Elapsed: 0:25:03.\n",
            "  Batch 1,320  of  2,085.    Elapsed: 0:25:50.\n",
            "  Batch 1,360  of  2,085.    Elapsed: 0:26:37.\n",
            "  Batch 1,400  of  2,085.    Elapsed: 0:27:24.\n",
            "  Batch 1,440  of  2,085.    Elapsed: 0:28:11.\n",
            "  Batch 1,480  of  2,085.    Elapsed: 0:28:58.\n",
            "  Batch 1,520  of  2,085.    Elapsed: 0:29:45.\n",
            "  Batch 1,560  of  2,085.    Elapsed: 0:30:32.\n",
            "  Batch 1,600  of  2,085.    Elapsed: 0:31:19.\n",
            "  Batch 1,640  of  2,085.    Elapsed: 0:32:06.\n",
            "  Batch 1,680  of  2,085.    Elapsed: 0:32:53.\n",
            "  Batch 1,720  of  2,085.    Elapsed: 0:33:40.\n",
            "  Batch 1,760  of  2,085.    Elapsed: 0:34:27.\n",
            "  Batch 1,800  of  2,085.    Elapsed: 0:35:14.\n",
            "  Batch 1,840  of  2,085.    Elapsed: 0:36:01.\n",
            "  Batch 1,880  of  2,085.    Elapsed: 0:36:48.\n",
            "  Batch 1,920  of  2,085.    Elapsed: 0:37:35.\n",
            "  Batch 1,960  of  2,085.    Elapsed: 0:38:22.\n",
            "  Batch 2,000  of  2,085.    Elapsed: 0:39:09.\n",
            "  Batch 2,040  of  2,085.    Elapsed: 0:39:56.\n",
            "  Batch 2,080  of  2,085.    Elapsed: 0:40:44.\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epcoh took: 0:40:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:03:50\n",
            "\n",
            "This model is to differentiate the '0' ratings from the '1' ratings.\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  2,085.    Elapsed: 0:00:47.\n",
            "  Batch    80  of  2,085.    Elapsed: 0:01:34.\n",
            "  Batch   120  of  2,085.    Elapsed: 0:02:21.\n",
            "  Batch   160  of  2,085.    Elapsed: 0:03:08.\n",
            "  Batch   200  of  2,085.    Elapsed: 0:03:55.\n",
            "  Batch   240  of  2,085.    Elapsed: 0:04:42.\n",
            "  Batch   280  of  2,085.    Elapsed: 0:05:29.\n",
            "  Batch   320  of  2,085.    Elapsed: 0:06:16.\n",
            "  Batch   360  of  2,085.    Elapsed: 0:07:03.\n",
            "  Batch   400  of  2,085.    Elapsed: 0:07:50.\n",
            "  Batch   440  of  2,085.    Elapsed: 0:08:37.\n",
            "  Batch   480  of  2,085.    Elapsed: 0:09:24.\n",
            "  Batch   520  of  2,085.    Elapsed: 0:10:11.\n",
            "  Batch   560  of  2,085.    Elapsed: 0:10:58.\n",
            "  Batch   600  of  2,085.    Elapsed: 0:11:46.\n",
            "  Batch   640  of  2,085.    Elapsed: 0:12:33.\n",
            "  Batch   680  of  2,085.    Elapsed: 0:13:20.\n",
            "  Batch   720  of  2,085.    Elapsed: 0:14:07.\n",
            "  Batch   760  of  2,085.    Elapsed: 0:14:54.\n",
            "  Batch   800  of  2,085.    Elapsed: 0:15:41.\n",
            "  Batch   840  of  2,085.    Elapsed: 0:16:29.\n",
            "  Batch   880  of  2,085.    Elapsed: 0:17:16.\n",
            "  Batch   920  of  2,085.    Elapsed: 0:18:03.\n",
            "  Batch   960  of  2,085.    Elapsed: 0:18:50.\n",
            "  Batch 1,000  of  2,085.    Elapsed: 0:19:37.\n",
            "  Batch 1,040  of  2,085.    Elapsed: 0:20:24.\n",
            "  Batch 1,080  of  2,085.    Elapsed: 0:21:12.\n",
            "  Batch 1,120  of  2,085.    Elapsed: 0:21:59.\n",
            "  Batch 1,160  of  2,085.    Elapsed: 0:22:46.\n",
            "  Batch 1,200  of  2,085.    Elapsed: 0:23:33.\n",
            "  Batch 1,240  of  2,085.    Elapsed: 0:24:20.\n",
            "  Batch 1,280  of  2,085.    Elapsed: 0:25:07.\n",
            "  Batch 1,320  of  2,085.    Elapsed: 0:25:54.\n",
            "  Batch 1,360  of  2,085.    Elapsed: 0:26:42.\n",
            "  Batch 1,400  of  2,085.    Elapsed: 0:27:29.\n",
            "  Batch 1,440  of  2,085.    Elapsed: 0:28:16.\n",
            "  Batch 1,480  of  2,085.    Elapsed: 0:29:03.\n",
            "  Batch 1,520  of  2,085.    Elapsed: 0:29:51.\n",
            "  Batch 1,560  of  2,085.    Elapsed: 0:30:38.\n",
            "  Batch 1,600  of  2,085.    Elapsed: 0:31:25.\n",
            "  Batch 1,640  of  2,085.    Elapsed: 0:32:12.\n",
            "  Batch 1,680  of  2,085.    Elapsed: 0:33:00.\n",
            "  Batch 1,720  of  2,085.    Elapsed: 0:33:47.\n",
            "  Batch 1,760  of  2,085.    Elapsed: 0:34:34.\n",
            "  Batch 1,800  of  2,085.    Elapsed: 0:35:21.\n",
            "  Batch 1,840  of  2,085.    Elapsed: 0:36:08.\n",
            "  Batch 1,880  of  2,085.    Elapsed: 0:36:55.\n",
            "  Batch 1,920  of  2,085.    Elapsed: 0:37:43.\n",
            "  Batch 1,960  of  2,085.    Elapsed: 0:38:30.\n",
            "  Batch 2,000  of  2,085.    Elapsed: 0:39:17.\n",
            "  Batch 2,040  of  2,085.    Elapsed: 0:40:04.\n",
            "  Batch 2,080  of  2,085.    Elapsed: 0:40:51.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:40:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:03:50\n",
            "\n",
            "This model is to differentiate the '0' ratings from the '1' ratings.\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  2,085.    Elapsed: 0:00:47.\n",
            "  Batch    80  of  2,085.    Elapsed: 0:01:34.\n",
            "  Batch   120  of  2,085.    Elapsed: 0:02:21.\n",
            "  Batch   160  of  2,085.    Elapsed: 0:03:08.\n",
            "  Batch   200  of  2,085.    Elapsed: 0:03:55.\n",
            "  Batch   240  of  2,085.    Elapsed: 0:04:43.\n",
            "  Batch   280  of  2,085.    Elapsed: 0:05:30.\n",
            "  Batch   320  of  2,085.    Elapsed: 0:06:17.\n",
            "  Batch   360  of  2,085.    Elapsed: 0:07:04.\n",
            "  Batch   400  of  2,085.    Elapsed: 0:07:51.\n",
            "  Batch   440  of  2,085.    Elapsed: 0:08:38.\n",
            "  Batch   480  of  2,085.    Elapsed: 0:09:25.\n",
            "  Batch   520  of  2,085.    Elapsed: 0:10:12.\n",
            "  Batch   560  of  2,085.    Elapsed: 0:10:59.\n",
            "  Batch   600  of  2,085.    Elapsed: 0:11:46.\n",
            "  Batch   640  of  2,085.    Elapsed: 0:12:33.\n",
            "  Batch   680  of  2,085.    Elapsed: 0:13:20.\n",
            "  Batch   720  of  2,085.    Elapsed: 0:14:07.\n",
            "  Batch   760  of  2,085.    Elapsed: 0:14:54.\n",
            "  Batch   800  of  2,085.    Elapsed: 0:15:41.\n",
            "  Batch   840  of  2,085.    Elapsed: 0:16:28.\n",
            "  Batch   880  of  2,085.    Elapsed: 0:17:15.\n",
            "  Batch   920  of  2,085.    Elapsed: 0:18:03.\n",
            "  Batch   960  of  2,085.    Elapsed: 0:18:50.\n",
            "  Batch 1,000  of  2,085.    Elapsed: 0:19:37.\n",
            "  Batch 1,040  of  2,085.    Elapsed: 0:20:24.\n",
            "  Batch 1,080  of  2,085.    Elapsed: 0:21:11.\n",
            "  Batch 1,120  of  2,085.    Elapsed: 0:21:58.\n",
            "  Batch 1,160  of  2,085.    Elapsed: 0:22:45.\n",
            "  Batch 1,200  of  2,085.    Elapsed: 0:23:32.\n",
            "  Batch 1,240  of  2,085.    Elapsed: 0:24:19.\n",
            "  Batch 1,280  of  2,085.    Elapsed: 0:25:06.\n",
            "  Batch 1,320  of  2,085.    Elapsed: 0:25:53.\n",
            "  Batch 1,360  of  2,085.    Elapsed: 0:26:40.\n",
            "  Batch 1,400  of  2,085.    Elapsed: 0:27:27.\n",
            "  Batch 1,440  of  2,085.    Elapsed: 0:28:14.\n",
            "  Batch 1,480  of  2,085.    Elapsed: 0:29:01.\n",
            "  Batch 1,520  of  2,085.    Elapsed: 0:29:48.\n",
            "  Batch 1,560  of  2,085.    Elapsed: 0:30:35.\n",
            "  Batch 1,600  of  2,085.    Elapsed: 0:31:22.\n",
            "  Batch 1,640  of  2,085.    Elapsed: 0:32:09.\n",
            "  Batch 1,680  of  2,085.    Elapsed: 0:32:56.\n",
            "  Batch 1,720  of  2,085.    Elapsed: 0:33:43.\n",
            "  Batch 1,760  of  2,085.    Elapsed: 0:34:30.\n",
            "  Batch 1,800  of  2,085.    Elapsed: 0:35:17.\n",
            "  Batch 1,840  of  2,085.    Elapsed: 0:36:05.\n",
            "  Batch 1,880  of  2,085.    Elapsed: 0:36:52.\n",
            "  Batch 1,920  of  2,085.    Elapsed: 0:37:39.\n",
            "  Batch 1,960  of  2,085.    Elapsed: 0:38:26.\n",
            "  Batch 2,000  of  2,085.    Elapsed: 0:39:13.\n",
            "  Batch 2,040  of  2,085.    Elapsed: 0:40:00.\n",
            "  Batch 2,080  of  2,085.    Elapsed: 0:40:47.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:40:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.69\n",
            "  Validation took: 0:03:50\n",
            "\n",
            "Training complete!\n",
            "Total training took 2:14:12 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-eo1OCY0fa9",
        "colab_type": "text"
      },
      "source": [
        "##### Differentiating ratings 1 and 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3O2bk5d0fHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "321e73d6-145d-441c-9e80-0a230d9cb706"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"This model is to differentiate the '0' ratings from the '1' ratings.\\n\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "    torch.save(model.state_dict(), './BERT_poor_epoch.pth')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "This model is to differentiate the '0' ratings from the '1' ratings.\n",
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    688.    Elapsed: 0:00:45.\n",
            "  Batch    80  of    688.    Elapsed: 0:01:32.\n",
            "  Batch   120  of    688.    Elapsed: 0:02:19.\n",
            "  Batch   160  of    688.    Elapsed: 0:03:07.\n",
            "  Batch   200  of    688.    Elapsed: 0:03:54.\n",
            "  Batch   240  of    688.    Elapsed: 0:04:41.\n",
            "  Batch   280  of    688.    Elapsed: 0:05:28.\n",
            "  Batch   320  of    688.    Elapsed: 0:06:16.\n",
            "  Batch   360  of    688.    Elapsed: 0:07:03.\n",
            "  Batch   400  of    688.    Elapsed: 0:07:51.\n",
            "  Batch   440  of    688.    Elapsed: 0:08:38.\n",
            "  Batch   480  of    688.    Elapsed: 0:09:26.\n",
            "  Batch   520  of    688.    Elapsed: 0:10:13.\n",
            "  Batch   560  of    688.    Elapsed: 0:11:00.\n",
            "  Batch   600  of    688.    Elapsed: 0:11:48.\n",
            "  Batch   640  of    688.    Elapsed: 0:12:35.\n",
            "  Batch   680  of    688.    Elapsed: 0:13:23.\n",
            "\n",
            "  Average training loss: 0.56\n",
            "  Training epcoh took: 0:13:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation Loss: 0.55\n",
            "  Validation took: 0:01:16\n",
            "\n",
            "This model is to differentiate the '0' ratings from the '1' ratings.\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    688.    Elapsed: 0:00:47.\n",
            "  Batch    80  of    688.    Elapsed: 0:01:35.\n",
            "  Batch   120  of    688.    Elapsed: 0:02:22.\n",
            "  Batch   160  of    688.    Elapsed: 0:03:09.\n",
            "  Batch   200  of    688.    Elapsed: 0:03:57.\n",
            "  Batch   240  of    688.    Elapsed: 0:04:44.\n",
            "  Batch   280  of    688.    Elapsed: 0:05:31.\n",
            "  Batch   320  of    688.    Elapsed: 0:06:19.\n",
            "  Batch   360  of    688.    Elapsed: 0:07:06.\n",
            "  Batch   400  of    688.    Elapsed: 0:07:53.\n",
            "  Batch   440  of    688.    Elapsed: 0:08:41.\n",
            "  Batch   480  of    688.    Elapsed: 0:09:28.\n",
            "  Batch   520  of    688.    Elapsed: 0:10:15.\n",
            "  Batch   560  of    688.    Elapsed: 0:11:03.\n",
            "  Batch   600  of    688.    Elapsed: 0:11:50.\n",
            "  Batch   640  of    688.    Elapsed: 0:12:38.\n",
            "  Batch   680  of    688.    Elapsed: 0:13:25.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:13:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation Loss: 0.53\n",
            "  Validation took: 0:01:16\n",
            "\n",
            "This model is to differentiate the '0' ratings from the '1' ratings.\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    688.    Elapsed: 0:00:47.\n",
            "  Batch    80  of    688.    Elapsed: 0:01:35.\n",
            "  Batch   120  of    688.    Elapsed: 0:02:22.\n",
            "  Batch   160  of    688.    Elapsed: 0:03:09.\n",
            "  Batch   200  of    688.    Elapsed: 0:03:56.\n",
            "  Batch   240  of    688.    Elapsed: 0:04:44.\n",
            "  Batch   280  of    688.    Elapsed: 0:05:31.\n",
            "  Batch   320  of    688.    Elapsed: 0:06:18.\n",
            "  Batch   360  of    688.    Elapsed: 0:07:05.\n",
            "  Batch   400  of    688.    Elapsed: 0:07:52.\n",
            "  Batch   440  of    688.    Elapsed: 0:08:39.\n",
            "  Batch   480  of    688.    Elapsed: 0:09:27.\n",
            "  Batch   520  of    688.    Elapsed: 0:10:14.\n",
            "  Batch   560  of    688.    Elapsed: 0:11:01.\n",
            "  Batch   600  of    688.    Elapsed: 0:11:48.\n",
            "  Batch   640  of    688.    Elapsed: 0:12:35.\n",
            "  Batch   680  of    688.    Elapsed: 0:13:22.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:13:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation Loss: 0.57\n",
            "  Validation took: 0:01:16\n",
            "\n",
            "This model is to differentiate the '0' ratings from the '1' ratings.\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    688.    Elapsed: 0:00:47.\n",
            "  Batch    80  of    688.    Elapsed: 0:01:34.\n",
            "  Batch   120  of    688.    Elapsed: 0:02:22.\n",
            "  Batch   160  of    688.    Elapsed: 0:03:09.\n",
            "  Batch   200  of    688.    Elapsed: 0:03:56.\n",
            "  Batch   240  of    688.    Elapsed: 0:04:43.\n",
            "  Batch   280  of    688.    Elapsed: 0:05:30.\n",
            "  Batch   320  of    688.    Elapsed: 0:06:17.\n",
            "  Batch   360  of    688.    Elapsed: 0:07:05.\n",
            "  Batch   400  of    688.    Elapsed: 0:07:52.\n",
            "  Batch   440  of    688.    Elapsed: 0:08:39.\n",
            "  Batch   480  of    688.    Elapsed: 0:09:26.\n",
            "  Batch   520  of    688.    Elapsed: 0:10:14.\n",
            "  Batch   560  of    688.    Elapsed: 0:11:01.\n",
            "  Batch   600  of    688.    Elapsed: 0:11:48.\n",
            "  Batch   640  of    688.    Elapsed: 0:12:35.\n",
            "  Batch   680  of    688.    Elapsed: 0:13:22.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:13:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "  Validation Loss: 0.64\n",
            "  Validation took: 0:01:16\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:59:17 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbo7tksFeqgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(model.state_dict(), \"./BERT_best_weights.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PY7JeqY8ZEa",
        "colab_type": "text"
      },
      "source": [
        "### XLM-RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0khsEPCi8c_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(transformer, max_len=512):\n",
        "    \n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "    cls_token = sequence_output[:, 0, :]\n",
        "    out = Dense(5, activation='softmax')(cls_token) # 5 ratings to predict\n",
        "    \n",
        "    model = Model(inputs=input_word_ids, outputs=out)\n",
        "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTASlFLl8gCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For tf.dataset\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# Configuration\n",
        "EPOCHS = 4\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "# MODEL = 'jplu/tf-xlm-roberta-large' # bert-base-multilingual-uncased\n",
        "MODEL = 'jplu/tf-xlm-roberta-base'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUo1BMtK8le4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = to_categorical(train_df['rating'], num_classes=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_iC7aME9y0l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bdc321f6-6b03-443b-9992-8406ba658a0c"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_df['review'],\n",
        "                                                  train_labels,\n",
        "                                                  stratify=train_labels,\n",
        "                                                  test_size=0.1,\n",
        "                                                  random_state=2020)\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((132067,), (14675,), (132067, 5), (14675, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAZNPlQW90FD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "3fe8713d275d4e6da1f16e75c3e3a2b1",
            "a7cf68d50bf44279b03f67d8858e7eef",
            "9a4e001132254db2ab4c32536cb3ad1a",
            "a9cbd3b4d1f34873b30bce694e327787",
            "a518d9bb967c429a884169d83242b9b1",
            "99a6ff12c8b04a57a9b4e5dd0922e438",
            "330cc60383ac4e328207d0fb95676bc2",
            "870acbee2bbe4df9b786bdbd247b5ebc",
            "fa089f6f160143d9bf4784c0a73bc543",
            "9b00fc2d521445debfafc60a5bf3db13",
            "b21de39c6ef44516bd7865753ef9872a",
            "1b55be8b4f1a482297e76e3844beecad",
            "8a93d028c0ec41b590fa0e04217c119b",
            "835384f11e7449569a99227b637d400b",
            "aa9bf006a03947ee9343b59fb663b0b7",
            "6684f06a158e47efa503a609b610d609"
          ]
        },
        "outputId": "cd8555f3-7334-4e99-b1c6-4a46d5464a9a"
      },
      "source": [
        "# load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fe8713d275d4e6da1f16e75c3e3a2b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa089f6f160143d9bf4784c0a73bc543",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NltWV_vE93yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 200\n",
        "\n",
        "X_train = regular_encode(X_train.values, tokenizer, maxlen=MAX_LEN)\n",
        "X_val = regular_encode(X_val.values, tokenizer, maxlen=MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPuvzcwj-Xkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((X_train, y_train))\n",
        "    .repeat()\n",
        "    .shuffle(1024)\n",
        "    .batch(BATCH_SIZE, drop_remainder = True)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "valid_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((X_val, y_val))\n",
        "    .batch(BATCH_SIZE, drop_remainder = True)\n",
        "    .cache()\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdPrywwJ-hG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485,
          "referenced_widgets": [
            "52c6cf331b3143e8868dff576b1199ac",
            "dc468847a0ff48f0be6c1f95c738b90a",
            "e9b2741590304a169d53335f9c6f42cb",
            "4f25478ff1a34e758e934109e10f8fd0",
            "eda53a1c2a1f43b886925ce83e64b13b",
            "67b19c08c7fb4481a5b5edc684de1116",
            "959bfb31f0b94392a8eca3f875e25570",
            "d5bae6633d314c01996359c1303a1117"
          ]
        },
        "outputId": "d0f06789-792b-4945-dab1-e63cac355c8b"
      },
      "source": [
        "%%time\n",
        "\n",
        "with strategy.scope():\n",
        "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
        "    model = build_model(transformer_layer, max_len=MAX_LEN)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52c6cf331b3143e8868dff576b1199ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1885418496.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_utils:Some weights of the model checkpoint at jplu/tf-xlm-roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_tf_utils:All the weights of TFRobertaModel were initialized from the model checkpoint at jplu/tf-xlm-roberta-base.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_word_ids (InputLayer)  [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "tf_roberta_model (TFRobertaM ((None, 200, 768), (None, 278043648 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice (T [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 3845      \n",
            "=================================================================\n",
            "Total params: 278,047,493\n",
            "Trainable params: 278,047,493\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 37.7 s, sys: 1min 19s, total: 1min 57s\n",
            "Wall time: 2min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUWuW6W9_DkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss',min_delta=0.0001, patience = 2)\n",
        "checkpoint = ModelCheckpoint(filepath=\"./checkpoints/XLMRoBERTa_best_weights_1.hdf5\",\n",
        "                             save_best_only = True,  # Only save a model if `val_loss` has improved.\n",
        "                             save_weights_only = True,\n",
        "                             monitor = \"val_loss\",\n",
        "                             verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOmrlu2L-0Zp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "f5d8956d-2996-4224-af78-c14872023992"
      },
      "source": [
        "steps = X_train.shape[0] // BATCH_SIZE\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch = steps,\n",
        "    validation_data = valid_dataset,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = [early_stop, checkpoint]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 192001536 elements. This may consume a large amount of memory.\n",
            "  num_elements)\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1031/1031 [==============================] - ETA: 0s - loss: 1.4431 - accuracy: 0.3212\n",
            "Epoch 00001: val_loss improved from inf to 1.17421, saving model to ./checkpoints/XLMRoBERTa_best_weights.hdf5\n",
            "1031/1031 [==============================] - 313s 303ms/step - loss: 1.4431 - accuracy: 0.3212 - val_loss: 1.1742 - val_accuracy: 0.4446\n",
            "Epoch 2/4\n",
            "1031/1031 [==============================] - ETA: 0s - loss: 1.1607 - accuracy: 0.4447\n",
            "Epoch 00002: val_loss improved from 1.17421 to 1.09825, saving model to ./checkpoints/XLMRoBERTa_best_weights.hdf5\n",
            "1031/1031 [==============================] - 293s 284ms/step - loss: 1.1607 - accuracy: 0.4447 - val_loss: 1.0983 - val_accuracy: 0.4730\n",
            "Epoch 3/4\n",
            "1031/1031 [==============================] - ETA: 0s - loss: 1.1017 - accuracy: 0.4709\n",
            "Epoch 00003: val_loss improved from 1.09825 to 1.08915, saving model to ./checkpoints/XLMRoBERTa_best_weights.hdf5\n",
            "1031/1031 [==============================] - 293s 285ms/step - loss: 1.1017 - accuracy: 0.4709 - val_loss: 1.0892 - val_accuracy: 0.4796\n",
            "Epoch 4/4\n",
            "1031/1031 [==============================] - ETA: 0s - loss: 1.0682 - accuracy: 0.4825\n",
            "Epoch 00004: val_loss improved from 1.08915 to 1.06443, saving model to ./checkpoints/XLMRoBERTa_best_weights.hdf5\n",
            "1031/1031 [==============================] - 294s 285ms/step - loss: 1.0682 - accuracy: 0.4825 - val_loss: 1.0644 - val_accuracy: 0.4864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4u9TVG6ZUvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3d36526-3312-4104-eefe-128af96ad53b"
      },
      "source": [
        "history.epoch[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bona7QeY-fB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "211e908b-254e-4458-ba23-c206f084ea6f"
      },
      "source": [
        "EPOCHS = 8\n",
        "\n",
        "history1 = model.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch = steps,\n",
        "    validation_data = valid_dataset,\n",
        "    initial_epoch = history.epoch[-1],\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = [early_stop, checkpoint]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/8\n",
            "1031/1031 [==============================] - ETA: 0s - loss: 1.0453 - accuracy: 0.4908\n",
            "Epoch 00004: val_loss improved from inf to 1.05862, saving model to ./checkpoints/XLMRoBERTa_best_weights_1.hdf5\n",
            "1031/1031 [==============================] - 297s 288ms/step - loss: 1.0453 - accuracy: 0.4908 - val_loss: 1.0586 - val_accuracy: 0.4859\n",
            "Epoch 5/8\n",
            "1031/1031 [==============================] - ETA: 0s - loss: 1.0269 - accuracy: 0.4960\n",
            "Epoch 00005: val_loss did not improve from 1.05862\n",
            "1031/1031 [==============================] - 288s 279ms/step - loss: 1.0269 - accuracy: 0.4960 - val_loss: 1.0599 - val_accuracy: 0.4911\n",
            "Epoch 6/8\n",
            "1031/1031 [==============================] - ETA: 0s - loss: 1.0098 - accuracy: 0.5038\n",
            "Epoch 00006: val_loss did not improve from 1.05862\n",
            "1031/1031 [==============================] - 287s 278ms/step - loss: 1.0098 - accuracy: 0.5038 - val_loss: 1.0671 - val_accuracy: 0.4884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0eeGhpRCcf2",
        "colab_type": "text"
      },
      "source": [
        "## Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v16hc8eJTMA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('./checkpoints/XLMRoBERTa_best_weights_5.hdf5')\n",
        "\n",
        "# device = torch.device('cpu')\n",
        "# model.load_state_dict(torch.load(\"./BERT_poor_epoch_2.pth\", map_location = device))\n",
        "# model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dA-T5qpCw0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "65aa97c1-46bd-4665-d933-39245435f701"
      },
      "source": [
        "print(len(test_raw))\n",
        "test_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Great danger, cool, motif and cantik2 jg model...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>One of the shades don't fit well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Very comfortable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Fast delivery. Product expiry is on Dec 2022. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>it's sooooo cute! i like playing with the glit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review\n",
              "0          1  Great danger, cool, motif and cantik2 jg model...\n",
              "1          2                   One of the shades don't fit well\n",
              "2          3                                   Very comfortable\n",
              "3          4  Fast delivery. Product expiry is on Dec 2022. ...\n",
              "4          5  it's sooooo cute! i like playing with the glit..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkjDFeyOCfED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "834313af-6d99-43dd-ae03-922a8e8e9636"
      },
      "source": [
        "test_raw['review'] = test_raw['review'].astype(str)\n",
        "test_raw['review'] = test_raw['review'].apply(lambda x: removestop(x))\n",
        "test_raw['review'] = test_raw['review'].apply(lambda x: clean_text(x))\n",
        "test_raw.loc[have_emoji_test_idx, 'review'] = test_raw.loc[have_emoji_test_idx, 'review'].apply(remove_emoji)\n",
        "test_raw.loc[repeated_rows_test, 'review'] = test_raw.loc[repeated_rows_test, 'review'].apply(delete_repeated_char)\n",
        "test_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>great danger cool motif cantik2 jg models deli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>one shades fit well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>comfortable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>fast delivery product expiry dec 2022 product ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>sooooo cute like playing glitters better brows...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review\n",
              "0          1  great danger cool motif cantik2 jg models deli...\n",
              "1          2                                one shades fit well\n",
              "2          3                                        comfortable\n",
              "3          4  fast delivery product expiry dec 2022 product ...\n",
              "4          5  sooooo cute like playing glitters better brows..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDD40k1pC5Ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = test_raw[\"review\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbg9X_GLj-j4",
        "colab_type": "text"
      },
      "source": [
        "##### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYs2szhJkKAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok.fit_on_texts(X_test)\n",
        "\n",
        "sequences = tok.texts_to_sequences(X_test)\n",
        "X_test = sequence.pad_sequences(sequences, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXuuJQ89Ddlp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f40a5098-9c4d-43c6-e219-6ae9a8c7ce85"
      },
      "source": [
        "print(len(X_test))\n",
        "X_test[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IVwU6V3EMgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c998ed9-e62e-418a-b4e9-95d27cca37db"
      },
      "source": [
        "a = np.array([X_test[0]])\n",
        "a.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 150)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsqBm5igDhNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model.predict(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCNSOPlMDzxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "059b8b4d-55ce-48bd-c948-8949769c56a1"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1gWir2mKHUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b0d6b23-2e27-4fb2-844b-c471d847b4e5"
      },
      "source": [
        "test_raw[\"review\"].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'great danger, cool, motif and cantik2 jg models. delivery cepet. tp packing less okay krn only wear clear plastic nerawang klihtan contents jd'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_in6af12GQjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "95dcfd23-812f-42bc-a35c-b962458c492e"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40020514, 0.2670463 , 0.2528953 , 0.04010465, 0.03974864]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPhPUfFNJ6YY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d05b069b-f70e-4503-fc80-4ab6d863cf0e"
      },
      "source": [
        "for x in range(len(test_raw)):\n",
        "    pred_arr = model.predict(np.array([X_test[x]]))\n",
        "    pred = np.argmax(pred_arr)\n",
        "    pred += 1\n",
        "    test_raw['review'].iloc[x] = pred\n",
        "\n",
        "test_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id review\n",
              "0          1      1\n",
              "1          2      5\n",
              "2          3      1\n",
              "3          4      5\n",
              "4          5      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfV_8hA8kT4O",
        "colab_type": "text"
      },
      "source": [
        "##### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RDQ00jtkXge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16d33b5b-0882-4e12-e32b-c5bd79ce36ec"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for rev in X_test:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(rev, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syRf8gfrkXRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8c6db90e-d482-4949-bb2d-d2071001db16"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for rev in X_test:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        rev,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 210,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation = True\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', X_test[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Great danger, cool, motif and cantik2 jg models. Delivery cepet. Tp packing less okay krn only wear clear plastic nerawang klihtan contents jd\n",
            "Token IDs: tensor([  101,  2307,  5473,  1010,  4658,  1010, 16226,  1998,  2064,  3775,\n",
            "         2243,  2475,  1046,  2290,  4275,  1012,  6959,  8292, 22327,  1012,\n",
            "         1056,  2361, 14743,  2625,  3100,  1047,  6826,  2069,  4929,  3154,\n",
            "         6081, 11265,  2527, 16600,  1047,  3669, 22893,  2078,  8417, 26219,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E0XR7AfMPPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "48724627-bb60-4aa8-cf8e-7c234e0b241e"
      },
      "source": [
        "attention_masks[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([210])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOESUZjaM_GU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b4d39153-56f9-447b-9d40-984bbb1cc689"
      },
      "source": [
        "input_ids[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([210])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW9tDUpNdovN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99OdCVuud_-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9acb5f8-cb5d-461a-f3bc-66291ad878bb"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions = []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "\n",
        "print('    DONE.')\n",
        "print(predictions[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 60,427 test sentences...\n",
            "    DONE.\n",
            "[array([[-1.9762735 ,  1.1098326 ,  1.5487819 ],\n",
            "       [-0.53538805,  1.3891801 ,  0.08182217],\n",
            "       [-1.3433073 ,  0.76564926,  1.3389164 ],\n",
            "       [-1.7738141 , -0.05901035,  1.9307495 ],\n",
            "       [-2.6973462 ,  0.2618049 ,  3.083851  ],\n",
            "       [ 0.5008199 ,  0.46554267, -0.5642729 ],\n",
            "       [-0.97600543,  0.58386415,  0.92295504],\n",
            "       [-1.969233  ,  0.6021631 ,  2.0228786 ],\n",
            "       [ 0.89161336,  0.40244585, -1.0836397 ],\n",
            "       [-1.0813419 ,  1.039094  ,  0.56280077],\n",
            "       [-0.07296357,  0.5264265 ,  0.14213072],\n",
            "       [-3.204545  , -0.96555424,  4.1598706 ],\n",
            "       [-2.0965064 ,  0.89095354,  1.7095503 ],\n",
            "       [-2.6045268 ,  0.44796553,  2.756565  ],\n",
            "       [-0.5306326 , -0.06775521,  1.0670553 ],\n",
            "       [-2.2410426 ,  0.50493515,  2.2955177 ],\n",
            "       [-1.8261654 ,  0.16447437,  2.3128324 ],\n",
            "       [ 2.5119457 , -0.18644196, -2.1477818 ],\n",
            "       [-2.024051  ,  0.18665072,  2.4822047 ],\n",
            "       [-0.17988753,  1.2505429 , -0.36887488],\n",
            "       [ 0.5364524 ,  0.48137793, -0.5790009 ],\n",
            "       [-1.4268203 ,  0.56272703,  1.5913024 ],\n",
            "       [-2.3840225 ,  0.80683243,  2.06879   ],\n",
            "       [-2.3970952 ,  0.15048347,  2.7534242 ],\n",
            "       [-1.9029689 ,  0.29727176,  1.8889121 ],\n",
            "       [-2.5811381 , -0.13227172,  3.036505  ],\n",
            "       [-3.1963015 , -0.4700265 ,  3.9072175 ],\n",
            "       [-1.5781845 ,  0.22205111,  1.9571065 ],\n",
            "       [-0.42725366,  0.9885845 ,  0.1311375 ],\n",
            "       [-0.41533104,  0.25944135,  0.4409113 ],\n",
            "       [-2.0124485 ,  0.7646615 ,  1.7371964 ],\n",
            "       [ 0.1308075 ,  0.2528095 ,  0.11471749]], dtype=float32), array([[-1.8332312 ,  0.33029163,  2.0225255 ],\n",
            "       [-0.3496641 , -0.11692385,  0.848261  ],\n",
            "       [-0.3781069 ,  0.79504603,  0.28802976],\n",
            "       [-3.2725735 , -0.61974996,  4.0018373 ],\n",
            "       [-2.4115782 ,  0.6811015 ,  2.481843  ],\n",
            "       [-2.136275  ,  0.61848587,  2.1389155 ],\n",
            "       [-2.8181517 ,  0.09890742,  3.032153  ],\n",
            "       [-0.5895566 ,  1.427405  , -0.11321228],\n",
            "       [-1.2511932 ,  0.52304465,  1.5409753 ],\n",
            "       [-1.802883  , -0.07591213,  2.1334164 ],\n",
            "       [-0.88226444,  1.0382056 ,  0.44273624],\n",
            "       [-1.825017  ,  0.7285841 ,  1.793492  ],\n",
            "       [-0.13631508,  0.28529486,  0.33506414],\n",
            "       [-0.9555132 ,  0.9890047 ,  0.6126785 ],\n",
            "       [-1.0641958 ,  0.7618934 ,  0.80392396],\n",
            "       [-2.3896244 ,  0.4502072 ,  2.2280278 ],\n",
            "       [-0.4409417 ,  0.3426335 ,  0.7256745 ],\n",
            "       [-0.23422246,  0.31019604,  0.34814453],\n",
            "       [-1.0769246 , -0.01393961,  1.4941844 ],\n",
            "       [-2.5570087 ,  0.5150789 ,  2.513612  ],\n",
            "       [-3.0664356 , -0.8441976 ,  3.981772  ],\n",
            "       [-2.985389  , -0.2969084 ,  3.5758154 ],\n",
            "       [-0.819054  ,  1.0751829 ,  0.41581142],\n",
            "       [-0.07427884,  0.34196487,  0.09931245],\n",
            "       [ 2.3931782 , -0.24186413, -1.9808657 ],\n",
            "       [ 0.17348954,  0.619528  , -0.27809682],\n",
            "       [-0.3756379 ,  0.13599114,  0.8208385 ],\n",
            "       [-0.40320626, -0.38175848,  1.3726588 ],\n",
            "       [ 0.5928378 ,  0.10754435, -0.08031759],\n",
            "       [-2.2816293 , -0.47956014,  3.172815  ],\n",
            "       [-1.6081018 ,  0.40267527,  1.7054574 ],\n",
            "       [-2.4324791 , -0.01514832,  2.6877756 ]], dtype=float32), array([[-1.3462524 ,  0.4105193 ,  1.5826896 ],\n",
            "       [-1.3687521 ,  1.3511355 ,  0.65017813],\n",
            "       [-2.3210404 ,  0.7343762 ,  2.1438591 ],\n",
            "       [-0.9485084 , -0.35718563,  1.737109  ],\n",
            "       [-0.9923655 ,  0.61841124,  0.987352  ],\n",
            "       [-1.9863883 ,  0.82881814,  1.8458468 ],\n",
            "       [ 2.0903494 , -0.09256215, -1.4682298 ],\n",
            "       [-2.1896367 ,  1.2282746 ,  1.6985614 ],\n",
            "       [-1.7041254 ,  1.0585018 ,  1.3904419 ],\n",
            "       [-2.2992675 ,  0.11003316,  2.5371616 ],\n",
            "       [-2.2940016 ,  0.86859936,  2.0735593 ],\n",
            "       [-1.6836674 ,  0.45316705,  1.6938076 ],\n",
            "       [-3.0121045 , -0.31234664,  3.644863  ],\n",
            "       [-2.8969326 ,  0.3854135 ,  2.9406264 ],\n",
            "       [ 0.6103091 ,  0.75002617, -0.85557723],\n",
            "       [-1.8750563 ,  0.55073726,  2.0183737 ],\n",
            "       [-1.9024764 ,  0.30503935,  2.1892934 ],\n",
            "       [-0.50975907,  0.50992066,  0.5388458 ],\n",
            "       [ 0.3345179 ,  0.72920054, -0.48933646],\n",
            "       [-2.9359553 , -1.0440214 ,  4.1204343 ],\n",
            "       [-1.3433073 ,  0.76564926,  1.3389164 ],\n",
            "       [-1.3439943 ,  1.2850679 ,  0.801651  ],\n",
            "       [-1.2280642 ,  0.16086562,  1.493347  ],\n",
            "       [-1.0909344 ,  0.832556  ,  0.9758271 ],\n",
            "       [ 0.23899846,  0.68134457, -0.42366174],\n",
            "       [ 1.1105012 ,  0.71699727, -1.1515527 ],\n",
            "       [-1.6777016 ,  0.08282849,  1.7904757 ],\n",
            "       [-0.43617624,  0.9770163 ,  0.1566317 ],\n",
            "       [-2.8511803 , -0.32555774,  3.2963474 ],\n",
            "       [-0.9096034 ,  0.2018366 ,  1.146592  ],\n",
            "       [ 1.2274822 , -0.6439496 , -0.22230974],\n",
            "       [-1.9715528 ,  0.87010455,  1.6739343 ]], dtype=float32), array([[-1.8826351 ,  0.65956736,  1.656757  ],\n",
            "       [-2.0468025 ,  0.3866103 ,  2.1203833 ],\n",
            "       [-3.0366223 ,  0.13218127,  3.261812  ],\n",
            "       [-1.1851171 ,  0.22831081,  1.5118356 ],\n",
            "       [-2.6402369 ,  0.7903507 ,  2.4674475 ],\n",
            "       [ 1.2092654 ,  0.28094357, -1.0888689 ],\n",
            "       [ 0.64553154, -0.7874453 ,  0.59419835],\n",
            "       [-1.8360221 ,  0.38158855,  1.8712457 ],\n",
            "       [-3.0012777 , -0.16059662,  3.402589  ],\n",
            "       [ 0.77832544,  0.5806135 , -0.8185752 ],\n",
            "       [-2.65884   ,  0.6108732 ,  2.56609   ],\n",
            "       [-1.9799262 , -0.44757912,  2.615633  ],\n",
            "       [-2.154194  ,  0.30899248,  2.0967104 ],\n",
            "       [-2.0189986 ,  0.2975221 ,  2.0984125 ],\n",
            "       [-2.178584  ,  0.59757215,  2.2246048 ],\n",
            "       [-2.1986914 ,  0.7084416 ,  1.9722884 ],\n",
            "       [-1.2802651 , -0.07207003,  1.6574068 ],\n",
            "       [-2.018851  ,  0.04433857,  2.4111702 ],\n",
            "       [-1.9457731 , -0.28175518,  2.4919045 ],\n",
            "       [-2.6888144 ,  0.42717972,  2.6694443 ],\n",
            "       [-0.87614596,  0.7711948 ,  0.7975319 ],\n",
            "       [-2.851337  , -0.00458645,  3.381571  ],\n",
            "       [-0.76587224,  1.0355291 ,  0.6940978 ],\n",
            "       [-0.9928944 ,  0.1570264 ,  1.3057412 ],\n",
            "       [-1.6622454 ,  0.3705416 ,  1.6140903 ],\n",
            "       [ 1.3010411 ,  0.6141943 , -1.2066875 ],\n",
            "       [-2.1860518 ,  0.35446167,  2.5406313 ],\n",
            "       [-1.4839762 ,  0.75272155,  1.4560431 ],\n",
            "       [-1.1873057 ,  0.586716  ,  1.2418654 ],\n",
            "       [-2.6710033 ,  0.26559132,  2.739044  ],\n",
            "       [-1.4238747 ,  0.77348185,  1.345811  ],\n",
            "       [ 1.9695808 ,  0.34075493, -1.7745181 ]], dtype=float32), array([[ 0.5302494 , -0.2443067 ,  0.3202795 ],\n",
            "       [-2.36381   ,  0.19438513,  2.4947875 ],\n",
            "       [-2.819234  , -0.25462162,  3.3426507 ],\n",
            "       [-2.0681694 ,  0.39405185,  2.1295893 ],\n",
            "       [-1.4775463 , -0.52749413,  2.2049184 ],\n",
            "       [-0.81602484,  0.64820755,  0.76510096],\n",
            "       [-1.7237124 ,  0.57062364,  1.7830262 ],\n",
            "       [-0.93477356,  3.5464091 , -1.7323103 ],\n",
            "       [-2.0750332 ,  0.45795015,  2.0234063 ],\n",
            "       [-1.697477  ,  1.1405711 ,  1.4450045 ],\n",
            "       [-2.524309  ,  0.06834009,  2.680908  ],\n",
            "       [-1.89338   ,  0.58596784,  1.8207842 ],\n",
            "       [-1.4244066 ,  0.543363  ,  1.5365901 ],\n",
            "       [-0.7974918 , -0.6115786 ,  1.560736  ],\n",
            "       [-1.8561362 ,  1.1480356 ,  1.389854  ],\n",
            "       [-1.5452633 , -0.10419884,  2.0739017 ],\n",
            "       [ 1.3013738 ,  0.39554593, -1.1579876 ],\n",
            "       [ 1.2080153 ,  0.25331926, -0.56342113],\n",
            "       [-1.3779107 ,  0.5022537 ,  1.2311022 ],\n",
            "       [-2.5013978 ,  1.0030583 ,  2.1594517 ],\n",
            "       [-0.6888298 ,  0.7867723 ,  0.35927317],\n",
            "       [-1.9360799 ,  0.5036842 ,  1.9275098 ],\n",
            "       [-2.3107636 ,  0.2601567 ,  2.2271452 ],\n",
            "       [-2.677033  ,  0.29511088,  2.70793   ],\n",
            "       [ 1.366628  ,  0.2293721 , -1.3718562 ],\n",
            "       [-2.0489655 ,  0.4586212 ,  2.1001368 ],\n",
            "       [-0.4628299 ,  0.5798014 ,  0.24826609],\n",
            "       [-2.8143008 ,  0.05886529,  3.042239  ],\n",
            "       [-1.380061  ,  1.164066  ,  0.754407  ],\n",
            "       [-0.8851137 ,  0.17781721,  1.2601081 ],\n",
            "       [ 0.15498765, -0.2199186 ,  0.26746568],\n",
            "       [-2.2726383 ,  0.97851175,  1.739077  ]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzQzLHRgtd9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b10a659b-61c2-4eb9-f0dd-dc8fc9cc8d36"
      },
      "source": [
        "pred_labels_i = np.argmax(predictions[0], axis=1).flatten()\n",
        "print(len(pred_labels_i))\n",
        "pred_labels_i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, 2, 2, 0, 2, 2, 0, 1, 1, 2, 2, 2, 2, 2, 2, 0, 2, 1, 0, 2,\n",
              "       2, 2, 2, 2, 2, 2, 1, 2, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii0pvT7tt3nH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f52ce060-8878-4914-87f9-ebfbd0df9225"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehflzb6I052G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df = test_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j98GfOIKd_dr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ef9405e4-c574-4345-944c-6c30fdff21eb"
      },
      "source": [
        "for x in range(len(predictions)):\n",
        "  pred_labels_i = np.argmax(predictions[x], axis=1).flatten()\n",
        "  for y in range(len(pred_labels_i)):\n",
        "    pred_labels_i[y] += 1\n",
        "    submission_df['review'].iloc[x*32+y] = pred_labels_i[y]\n",
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id review\n",
              "0          1      2\n",
              "1          2      1\n",
              "2          3      2\n",
              "3          4      2\n",
              "4          5      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYQf6XyX-IOf",
        "colab_type": "text"
      },
      "source": [
        "##### XLM-RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skCn1zV1-LCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = regular_encode(test_raw['review'].values, tokenizer, maxlen=MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUVsgzNn-Pnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices(X_test)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K47lcz_e-Pj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "165b5948-1b52-44af-c3cc-ef3f297be3e9"
      },
      "source": [
        "pred = model.predict(test_dataset, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "473/473 [==============================] - 39s 82ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufliqzcaHO4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('xlm-roberta_5', pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uOcBJI1HOyX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5c13624-3719-4c19-a25e-06c82de46935"
      },
      "source": [
        "pred = np.argmax(pred, axis=1)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 4 ... 4 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dbGpd-jHh8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "a36e5284-47d8-424b-d522-639805ba7331"
      },
      "source": [
        "submission_df = pd.DataFrame({'review_id': test_raw['review_id'],\n",
        "                           'rating': pred})\n",
        "submission_df.head(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60421</th>\n",
              "      <td>60422</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60422</th>\n",
              "      <td>60423</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60423</th>\n",
              "      <td>60424</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60424</th>\n",
              "      <td>60425</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60425</th>\n",
              "      <td>60426</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60426 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       review_id  rating\n",
              "0              1       2\n",
              "1              2       2\n",
              "2              3       4\n",
              "3              4       4\n",
              "4              5       4\n",
              "...          ...     ...\n",
              "60421      60422       4\n",
              "60422      60423       4\n",
              "60423      60424       2\n",
              "60424      60425       4\n",
              "60425      60426       4\n",
              "\n",
              "[60426 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAool2vvgIYM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8a64a8b1-77ea-444b-9bc1-403a0d623078"
      },
      "source": [
        "rating_mapper_decode = {0: 1,\n",
        "                        1: 2,\n",
        "                        2: 3,\n",
        "                        3: 4,\n",
        "                        4: 5}\n",
        "\n",
        "submission_df['rating'] = submission_df['rating'].map(rating_mapper_decode)\n",
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id  rating\n",
              "0          1       3\n",
              "1          2       3\n",
              "2          3       5\n",
              "3          4       5\n",
              "4          5       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmPPDlqHgt-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "bbe72814-34f4-4ce8-cc03-19e7463c0b75"
      },
      "source": [
        "submission_df[submission_df['rating']==5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60421</th>\n",
              "      <td>60422</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60422</th>\n",
              "      <td>60423</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60424</th>\n",
              "      <td>60425</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60425</th>\n",
              "      <td>60426</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60426</th>\n",
              "      <td>60427</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38531 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       review_id  rating\n",
              "2              3       5\n",
              "3              4       5\n",
              "4              5       5\n",
              "6              7       5\n",
              "7              8       5\n",
              "...          ...     ...\n",
              "60421      60422       5\n",
              "60422      60423       5\n",
              "60424      60425       5\n",
              "60425      60426       5\n",
              "60426      60427       5\n",
              "\n",
              "[38531 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9PRl7-mHjEn",
        "colab_type": "text"
      },
      "source": [
        "### Post-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5nDdNUhKeLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "82194751-d7fa-4190-e176-c752dddd3ab9"
      },
      "source": [
        "submission_df.columns = ['review_id', 'rating']\n",
        "submission_df.head(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60421</th>\n",
              "      <td>60422</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60422</th>\n",
              "      <td>60423</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60423</th>\n",
              "      <td>60424</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60424</th>\n",
              "      <td>60425</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60425</th>\n",
              "      <td>60426</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60426 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       review_id  rating\n",
              "0              1       5\n",
              "1              2       3\n",
              "2              3       5\n",
              "3              4       5\n",
              "4              5       5\n",
              "...          ...     ...\n",
              "60421      60422       1\n",
              "60422      60423       5\n",
              "60423      60424       3\n",
              "60424      60425       5\n",
              "60425      60426       5\n",
              "\n",
              "[60426 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqILG3Z76vUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "ae510c29-e12a-40aa-d6ee-e81ac46dee35"
      },
      "source": [
        "test_raw = pd.merge(test_raw, submission_df, on='review_id')\n",
        "print(len(test_raw))\n",
        "test_raw.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Great danger, cool, motif and cantik2 jg model...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>One of the shades don't fit well</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Very comfortable</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Fast delivery. Product expiry is on Dec 2022. ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>it's sooooo cute! i like playing with the glit...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>They 're about a 1/2 inch longer than the broo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>The quality not good and receved the slipper i...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Nice quality of Cotton &amp; cute .. design .. acc...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>which is easy as can be ( just lifting up the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Shipping was fast too soon, ordered Tuesday to...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>Thanks, we have received partnered package wel...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>Excellent product quality excellent product p...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>Trimakasih can pen cheap price, the quality is...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>Great support and comfortable .</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>To run through the shop to buy always the rain...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>Very nice. Thank you 😊</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>overall excellent shoe .</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>Uda waiting lma unfortnately his reply on mess...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>Love these shoes .</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>The deliery is fast, but the filter seems to b...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    review_id                                             review  rating\n",
              "0           1  Great danger, cool, motif and cantik2 jg model...       5\n",
              "1           2                   One of the shades don't fit well       3\n",
              "2           3                                   Very comfortable       5\n",
              "3           4  Fast delivery. Product expiry is on Dec 2022. ...       5\n",
              "4           5  it's sooooo cute! i like playing with the glit...       5\n",
              "5           6  They 're about a 1/2 inch longer than the broo...       1\n",
              "6           7  The quality not good and receved the slipper i...       5\n",
              "7           8  Nice quality of Cotton & cute .. design .. acc...       5\n",
              "8           9  which is easy as can be ( just lifting up the ...       1\n",
              "9          10  Shipping was fast too soon, ordered Tuesday to...       3\n",
              "10         11  Thanks, we have received partnered package wel...       3\n",
              "11         12   Excellent product quality excellent product p...       5\n",
              "12         13  Trimakasih can pen cheap price, the quality is...       5\n",
              "13         14                    Great support and comfortable .       5\n",
              "14         15  To run through the shop to buy always the rain...       5\n",
              "15         16                             Very nice. Thank you 😊       5\n",
              "16         17                           overall excellent shoe .       5\n",
              "17         18  Uda waiting lma unfortnately his reply on mess...       1\n",
              "18         19                                 Love these shoes .       5\n",
              "19         20  The deliery is fast, but the filter seems to b...       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyoQRqA9buxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids.to(device)\n",
        "attention_masks.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gt36UBx7ULH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "35e87b18-4319-44bb-da54-f570c0f22739"
      },
      "source": [
        "for i in range(len(test_raw)):\n",
        "  if test_raw['rating'].iloc[i] == 1:\n",
        "    b = input_ids[i].shape[0]\n",
        "    a = torch.reshape(input_ids[i], (1,b))\n",
        "    c = torch.reshape(input_ids[i], (1,b))\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(a, token_type_ids=None, \n",
        "                        attention_mask=c)\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    pred_labels = np.argmax(logits, axis=1).flatten()\n",
        "    pred_labels += 1\n",
        "    submission_df['rating'].iloc[i] = pred_labels\n",
        "\n",
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id  rating\n",
              "0          1       5\n",
              "1          2       3\n",
              "2          3       5\n",
              "3          4       5\n",
              "4          5       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkiuWtKWvFOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_5lab(x):\n",
        "  if x == 0:\n",
        "    return 1\n",
        "  elif x == 1:\n",
        "    return 3\n",
        "  elif x == 2:\n",
        "    return 5\n",
        "  else:\n",
        "    print(\"Warning: number not in range.\", x, \" was called to function to_5lab().\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDj9C0KdvtaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "90df78e8-c076-4c5a-a1be-b28226d45f41"
      },
      "source": [
        "submission_df['rating'] = submission_df['rating'].apply(lambda x: to_5lab(x))\n",
        "submission_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id  rating\n",
              "0          1       5\n",
              "1          2       3\n",
              "2          3       5\n",
              "3          4       5\n",
              "4          5       5\n",
              "5          6       1\n",
              "6          7       5\n",
              "7          8       5\n",
              "8          9       1\n",
              "9         10       3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cul2ATWzQpws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df.to_csv('submission.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}